{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "longcat (generic function with 1 method)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "include(\"ultrasoundgeneration.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40-element Array{String,1}:\n",
       " \"Pancreas_14.nrrd\"\n",
       " \"Pancreas_15.nrrd\"\n",
       " \"Pancreas_16.nrrd\"\n",
       " \"Pancreas_17.nrrd\"\n",
       " \"Pancreas_18.nrrd\"\n",
       " \"Pancreas_19.nrrd\"\n",
       " \"Pancreas_20.nrrd\"\n",
       " \"Pancreas_21.nrrd\"\n",
       " \"Pancreas_22.nrrd\"\n",
       " \"Pancreas_23.nrrd\"\n",
       " \"Pancreas_24.nrrd\"\n",
       " \"Pancreas_25.nrrd\"\n",
       " \"Pancreas_26.nrrd\"\n",
       " â‹®                 \n",
       " \"Pancreas_42.nrrd\"\n",
       " \"Pancreas_43.nrrd\"\n",
       " \"Pancreas_44.nrrd\"\n",
       " \"Pancreas_45.nrrd\"\n",
       " \"Pancreas_46.nrrd\"\n",
       " \"Pancreas_47.nrrd\"\n",
       " \"Pancreas_48.nrrd\"\n",
       " \"Pancreas_49.nrrd\"\n",
       " \"Pancreas_50.nrrd\"\n",
       " \"Pancreas_51.nrrd\"\n",
       " \"Pancreas_52.nrrd\"\n",
       " \"Pancreas_53.nrrd\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using PyCall\n",
    "pushfirst!(PyVector(pyimport(\"sys\").\"path\"), \"\")\n",
    "ultrasoundgeneration = pyimport(\"ultrasoundgeneration\")\n",
    "\n",
    "names = readdir(ultrasoundgeneration.train_volumes_path)[1:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pancreas_14.nrrdPancreas_15.nrrdPancreas_16.nrrdPancreas_17.nrrdPancreas_18.nrrdPancreas_19.nrrdPancreas_20.nrrdPancreas_21.nrrdPancreas_22.nrrdPancreas_23.nrrdPancreas_24.nrrdPancreas_25.nrrdPancreas_26.nrrdPancreas_27.nrrdPancreas_28.nrrdPancreas_29.nrrdPancreas_30.nrrdPancreas_31.nrrdPancreas_32.nrrdPancreas_33.nrrdPancreas_34.nrrdPancreas_35.nrrdPancreas_36.nrrdPancreas_37.nrrdPancreas_38.nrrdPancreas_39.nrrdPancreas_40.nrrdPancreas_41.nrrdPancreas_42.nrrdPancreas_43.nrrdPancreas_44.nrrdPancreas_45.nrrdPancreas_46.nrrdPancreas_47.nrrdPancreas_48.nrrdPancreas_49.nrrdPancreas_50.nrrdPancreas_51.nrrdPancreas_52.nrrdPancreas_53.nrrd"
     ]
    }
   ],
   "source": [
    "struct AnnotatedImage\n",
    "    image::ItkImage\n",
    "    annotation::Array{Array{Float64,1},1}\n",
    "end\n",
    "\n",
    "\n",
    "annotated_images = Array{AnnotatedImage, 1}()\n",
    "for name = names\n",
    "    print(name)\n",
    "    image, annotation = ultrasoundgeneration.load_image_annotation(\n",
    "        name, ultrasoundgeneration.train_volumes_path)\n",
    "    jimage = ItkImage(image)\n",
    "    push!(annotated_images, AnnotatedImage(jimage, annotation))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pancreas_10.nrrdPancreas_11.nrrdPancreas_12.nrrdPancreas_13.nrrdPancreas_6.nrrdPancreas_7.nrrdPancreas_8.nrrdPancreas_9.nrrd"
     ]
    }
   ],
   "source": [
    "t_annotated_images = Array{AnnotatedImage, 1}()\n",
    "for name = readdir(ultrasoundgeneration.test_volumes_path)\n",
    "    print(name)\n",
    "    image, annotation = ultrasoundgeneration.load_image_annotation(\n",
    "        name, ultrasoundgeneration.test_volumes_path)\n",
    "    jimage = ItkImage(image)\n",
    "    push!(t_annotated_images, AnnotatedImage(jimage, annotation))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "Figure(PyObject <Figure size 640x480 with 2 Axes>)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "PyObject <matplotlib.colorbar.Colorbar object at 0x7f17db42de48>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using PyPlot\n",
    "i += 1\n",
    "t = generate_sample(annotated_images[i].image, annotated_images[i].annotation)\n",
    "plt.imshow(t[\"data\"][1])\n",
    "colorbar()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PyObject <module 'train_network_withangle' from '/media/data/hastings/ct-angledslice-align/train_network_withangle.py'>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_parallel = pyimport(\"train_network_withangle\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-24 22:49:18.877076: W tensorflow/core/util/tensor_slice_reader.cc:95] Could not open models/includeangle: Data loss: not an sstable (bad magic number): perhaps your file is in a different file format and you need to use a different restore operator?\n"
     ]
    }
   ],
   "source": [
    "network_parallel.model.load_weights(\"models/includeangle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i  2.512279 seconds (2.97 M allocations: 2.333 GiB, 24.06% gc time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time tdata, tclasses = generate_data(\n",
    "    [x.image for x in t_annotated_images],\n",
    "    [x.annotation for x in t_annotated_images]\n",
    ")\n",
    "tdata = longcat(tdata)\n",
    "tclasses = longcat(tclasses)\n",
    "0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 17s - loss: 0.2326 - val_loss: 3.1308\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2625 - val_loss: 0.8404\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2461 - val_loss: 2.0968\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2503 - val_loss: 0.3785\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2735 - val_loss: 0.5213\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2413 - val_loss: 0.2343\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2262 - val_loss: 2.3456\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2207 - val_loss: 0.3144\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2249 - val_loss: 1.9785\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2336 - val_loss: 0.2242\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2139 - val_loss: 0.2980\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2587 - val_loss: 0.5858\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2662 - val_loss: 0.3390\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2396 - val_loss: 0.3195\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2437 - val_loss: 0.3260\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.1941 - val_loss: 0.4703\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2623 - val_loss: 0.3106\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2182 - val_loss: 0.1982\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2257 - val_loss: 0.5371\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2230 - val_loss: 0.2660\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2247 - val_loss: 0.3208\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2391 - val_loss: 0.3458\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2766 - val_loss: 2.5075\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1909 - val_loss: 0.2084\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2356 - val_loss: 0.2348\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2419 - val_loss: 0.4218\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2042 - val_loss: 0.4413\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2158 - val_loss: 0.2797\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2029 - val_loss: 1.1201\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2488 - val_loss: 0.9581\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2387 - val_loss: 0.9978\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2466 - val_loss: 0.3772\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2009 - val_loss: 0.1605\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.1797 - val_loss: 0.2543\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2338 - val_loss: 0.7468\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2572 - val_loss: 0.8305\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2608 - val_loss: 0.3983\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2582 - val_loss: 0.3222\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2033 - val_loss: 0.2023\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2012 - val_loss: 0.2255\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.1938 - val_loss: 0.5122\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2457 - val_loss: 0.3038\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2268 - val_loss: 0.3434\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2329 - val_loss: 0.4032\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2336 - val_loss: 0.7933\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2649 - val_loss: 0.1991\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.1902 - val_loss: 0.5824\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2228 - val_loss: 1.1317\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2257 - val_loss: 3.2292\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2200 - val_loss: 0.9648\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2268 - val_loss: 1.4022\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.1922 - val_loss: 0.3257\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2529 - val_loss: 2.4694\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2084 - val_loss: 0.7860\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2279 - val_loss: 0.5353\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2205 - val_loss: 0.3323\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2091 - val_loss: 2.7699\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2607 - val_loss: 0.2851\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2782 - val_loss: 0.2239\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2133 - val_loss: 3.2997\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2289 - val_loss: 0.2605\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2183 - val_loss: 0.2280\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2237 - val_loss: 1.7942\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2523 - val_loss: 0.8057\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2322 - val_loss: 0.9009\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2128 - val_loss: 0.9239\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2349 - val_loss: 1.3720\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.2439 - val_loss: 0.3715\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.2086 - val_loss: 1.4801\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2271 - val_loss: 0.2413\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.1959 - val_loss: 1.0643\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2465 - val_loss: 0.5604\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2368 - val_loss: 0.6057\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1959 - val_loss: 0.5382\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2196 - val_loss: 0.7413\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2089 - val_loss: 2.5307\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2041 - val_loss: 0.5693\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2173 - val_loss: 0.3954\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2174 - val_loss: 0.6277\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2410 - val_loss: 1.8576\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2572 - val_loss: 0.8289\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2324 - val_loss: 0.9154\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2424 - val_loss: 0.5770\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2642 - val_loss: 0.5160\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2283 - val_loss: 0.3784\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2042 - val_loss: 0.3775\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2219 - val_loss: 0.3195\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2106 - val_loss: 1.1073\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2369 - val_loss: 0.3451\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2240 - val_loss: 0.2050\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2379 - val_loss: 0.7269\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2050 - val_loss: 0.3741\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2480 - val_loss: 2.0575\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2322 - val_loss: 0.3786\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.1877 - val_loss: 1.0054\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2126 - val_loss: 2.9104\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2045 - val_loss: 0.4332\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.2220 - val_loss: 0.2255\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.2241 - val_loss: 0.6443\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2284 - val_loss: 0.3305\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2226 - val_loss: 1.2868\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2256 - val_loss: 2.4152\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.2247 - val_loss: 0.2635\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.2500 - val_loss: 0.5749\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.1962 - val_loss: 0.3284\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2102 - val_loss: 1.1322\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2169 - val_loss: 0.9161\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2143 - val_loss: 0.3663\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2091 - val_loss: 0.6334\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2206 - val_loss: 0.2612\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2457 - val_loss: 0.4603\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2194 - val_loss: 0.6116\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2477 - val_loss: 0.8625\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2232 - val_loss: 1.2483\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2437 - val_loss: 0.3095\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2120 - val_loss: 0.2956\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1837 - val_loss: 0.3135\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.1812 - val_loss: 0.3516\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2233 - val_loss: 0.1808\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2139 - val_loss: 1.0567\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2905 - val_loss: 0.6013\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2366 - val_loss: 1.3989\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2201 - val_loss: 0.7816\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2079 - val_loss: 0.2202\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.1922 - val_loss: 1.5176\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.1841 - val_loss: 1.0392\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2054 - val_loss: 1.5468\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1978 - val_loss: 0.2816\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2195 - val_loss: 0.3736\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2409 - val_loss: 0.4991\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2055 - val_loss: 4.2689\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2071 - val_loss: 1.1702\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2023 - val_loss: 3.1268\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.1910 - val_loss: 0.1893\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2077 - val_loss: 0.7223\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.1888 - val_loss: 0.6308\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.1999 - val_loss: 0.4672\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2219 - val_loss: 0.8384\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2423 - val_loss: 0.7277\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.1957 - val_loss: 2.9966\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.1974 - val_loss: 0.1969\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2030 - val_loss: 0.2484\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2474 - val_loss: 0.2920\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2575 - val_loss: 1.0332\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2149 - val_loss: 2.1200\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2443 - val_loss: 0.2601\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2294 - val_loss: 2.0811\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2097 - val_loss: 1.3329\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2056 - val_loss: 0.7338\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2320 - val_loss: 0.5209\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2072 - val_loss: 0.3366\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2217 - val_loss: 3.3451\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2282 - val_loss: 0.7788\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2282 - val_loss: 0.3230\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2273 - val_loss: 0.6395\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2175 - val_loss: 0.3413\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2240 - val_loss: 0.1962\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2126 - val_loss: 1.6534\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.1994 - val_loss: 0.1605\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2332 - val_loss: 0.3309\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2019 - val_loss: 0.4180\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2128 - val_loss: 0.3465\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.1975 - val_loss: 0.6071\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2285 - val_loss: 0.3226\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1986 - val_loss: 0.3251\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2237 - val_loss: 0.3932\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2294 - val_loss: 0.6481\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2105 - val_loss: 0.4406\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2048 - val_loss: 1.3095\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2202 - val_loss: 0.2327\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2044 - val_loss: 0.3970\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2266 - val_loss: 0.3228\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2269 - val_loss: 2.3876\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2406 - val_loss: 0.2750\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2120 - val_loss: 1.5869\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2263 - val_loss: 0.2921\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2218 - val_loss: 0.3017\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1984 - val_loss: 0.6663\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2129 - val_loss: 0.4514\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2386 - val_loss: 0.4380\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2099 - val_loss: 0.2902\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2132 - val_loss: 2.8928\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2111 - val_loss: 0.7490\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1635 - val_loss: 0.3072\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2137 - val_loss: 0.4801\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2482 - val_loss: 0.2522\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2060 - val_loss: 0.1677\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1970 - val_loss: 2.2683\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2251 - val_loss: 0.2322\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2061 - val_loss: 0.2560\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2177 - val_loss: 0.2796\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1902 - val_loss: 0.2196\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2284 - val_loss: 0.5209\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2231 - val_loss: 2.3468\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1972 - val_loss: 0.3229\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2577 - val_loss: 0.1963\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2135 - val_loss: 2.3660\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2345 - val_loss: 0.4869\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1911 - val_loss: 0.8070\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2077 - val_loss: 0.3125\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2278 - val_loss: 1.4139\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2478 - val_loss: 0.6298\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2046 - val_loss: 0.5856\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2437 - val_loss: 2.5369\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2248 - val_loss: 0.3765\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2354 - val_loss: 0.2805\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1922 - val_loss: 0.1939\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2069 - val_loss: 0.4594\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1993 - val_loss: 0.8608\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2065 - val_loss: 0.2509\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2349 - val_loss: 0.3959\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2359 - val_loss: 0.6248\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2182 - val_loss: 0.3184\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2102 - val_loss: 0.2558\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2160 - val_loss: 0.9410\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2584 - val_loss: 0.8145\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2483 - val_loss: 0.6567\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.2233 - val_loss: 0.6170\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.1973 - val_loss: 1.0287\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.2243 - val_loss: 0.7568\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.2234 - val_loss: 0.1975\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.2310 - val_loss: 1.6911\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.2240 - val_loss: 1.6023\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.1968 - val_loss: 0.1984\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.2008 - val_loss: 1.1300\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.2437 - val_loss: 0.2175\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2340 - val_loss: 3.0193\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1865 - val_loss: 3.5449\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2423 - val_loss: 1.0688\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1994 - val_loss: 0.2157\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1838 - val_loss: 0.5326\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.1957 - val_loss: 0.4997\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2190 - val_loss: 1.0143\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1913 - val_loss: 0.2054\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2172 - val_loss: 0.8967\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2097 - val_loss: 0.3975\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2056 - val_loss: 0.5756\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2368 - val_loss: 0.2461\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.1932 - val_loss: 0.4116\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2515 - val_loss: 0.3351\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2271 - val_loss: 0.2243\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2002 - val_loss: 0.8899\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2261 - val_loss: 0.5533\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2111 - val_loss: 0.4477\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2234 - val_loss: 0.9610\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2295 - val_loss: 0.5228\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2302 - val_loss: 0.3345\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2083 - val_loss: 0.7313\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2460 - val_loss: 0.3110\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2072 - val_loss: 0.8223\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2506 - val_loss: 0.7088\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2023 - val_loss: 1.5941\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2453 - val_loss: 0.2513\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2247 - val_loss: 0.9065\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2561 - val_loss: 1.4199\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2182 - val_loss: 0.5654\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2096 - val_loss: 1.3697\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1980 - val_loss: 0.5092\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2084 - val_loss: 1.0838\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2627 - val_loss: 1.0833\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2360 - val_loss: 0.5243\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2575 - val_loss: 0.2579\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2231 - val_loss: 0.3168\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1963 - val_loss: 0.8670\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2207 - val_loss: 0.2164\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1996 - val_loss: 0.7613\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1901 - val_loss: 0.2091\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2016 - val_loss: 0.3087\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2201 - val_loss: 0.5054\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2085 - val_loss: 0.4368\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2121 - val_loss: 0.2421\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2348 - val_loss: 2.3215\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2363 - val_loss: 0.2105\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2416 - val_loss: 0.6066\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.2366 - val_loss: 0.2517\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.2131 - val_loss: 0.2893\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.1880 - val_loss: 0.3424\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2215 - val_loss: 0.5281\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.1959 - val_loss: 1.0942\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2233 - val_loss: 2.0975\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2167 - val_loss: 1.3049\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.1803 - val_loss: 0.8755\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2217 - val_loss: 0.4905\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2002 - val_loss: 0.3392\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2186 - val_loss: 0.4403\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2445 - val_loss: 0.4361\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.1998 - val_loss: 0.2827\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2210 - val_loss: 2.7601\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2129 - val_loss: 1.7597\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2084 - val_loss: 0.2322\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2114 - val_loss: 0.4608\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2211 - val_loss: 1.6270\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2253 - val_loss: 0.3787\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.1936 - val_loss: 0.6939\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2438 - val_loss: 3.9317\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2021 - val_loss: 4.1147\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2328 - val_loss: 0.3081\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2128 - val_loss: 0.4026\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2625 - val_loss: 0.9072\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2237 - val_loss: 0.7176\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2325 - val_loss: 0.4185\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2087 - val_loss: 0.5456\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2490 - val_loss: 0.2975\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2268 - val_loss: 0.2160\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2362 - val_loss: 1.8617\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2040 - val_loss: 1.2805\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2152 - val_loss: 0.2528\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2057 - val_loss: 0.8112\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2231 - val_loss: 0.3232\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.1982 - val_loss: 1.4279\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2176 - val_loss: 0.3284\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2104 - val_loss: 0.2253\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1912 - val_loss: 0.2629\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.1983 - val_loss: 0.2043\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2171 - val_loss: 3.8625\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2002 - val_loss: 0.6493\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.1792 - val_loss: 0.5465\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2376 - val_loss: 1.5036\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2158 - val_loss: 0.4615\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2136 - val_loss: 3.3152\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2464 - val_loss: 0.4873\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.1937 - val_loss: 0.2710\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2277 - val_loss: 0.3964\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2215 - val_loss: 0.1956\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2108 - val_loss: 0.7311\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1973 - val_loss: 0.4114\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2086 - val_loss: 0.2002\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2505 - val_loss: 0.3729\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2608 - val_loss: 0.9109\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2369 - val_loss: 2.1569\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2277 - val_loss: 0.3078\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2342 - val_loss: 0.1930\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2023 - val_loss: 1.5309\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2460 - val_loss: 0.3980\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2213 - val_loss: 1.5611\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2172 - val_loss: 1.7474\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2328 - val_loss: 0.3977\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2122 - val_loss: 0.2072\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2388 - val_loss: 0.5045\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.2245 - val_loss: 0.2203\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.2107 - val_loss: 3.1970\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.1968 - val_loss: 0.3028\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2268 - val_loss: 0.4177\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2298 - val_loss: 0.5501\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2428 - val_loss: 0.3276\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2142 - val_loss: 0.5140\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2594 - val_loss: 0.5779\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2089 - val_loss: 0.5050\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2283 - val_loss: 1.0662\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1906 - val_loss: 0.6802\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2022 - val_loss: 0.5598\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2305 - val_loss: 1.4012\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2082 - val_loss: 1.3494\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2194 - val_loss: 0.7054\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2205 - val_loss: 0.8508\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2225 - val_loss: 0.5949\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2259 - val_loss: 0.2872\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2224 - val_loss: 2.6900\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2089 - val_loss: 0.3708\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1950 - val_loss: 0.4312\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2153 - val_loss: 0.7500\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2079 - val_loss: 0.3568\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2085 - val_loss: 0.5498\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2351 - val_loss: 3.2117\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2275 - val_loss: 0.2231\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2356 - val_loss: 1.7779\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2250 - val_loss: 0.6525\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2255 - val_loss: 0.2959\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.1931 - val_loss: 0.2047\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2210 - val_loss: 0.2421\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.1944 - val_loss: 0.2950\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2078 - val_loss: 0.2581\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.1886 - val_loss: 0.2830\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2114 - val_loss: 1.6803\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1972 - val_loss: 3.2978\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2270 - val_loss: 1.3206\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.2114 - val_loss: 1.0562\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2210 - val_loss: 0.5559\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.2288 - val_loss: 0.5710\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.2170 - val_loss: 1.3143\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1886 - val_loss: 0.5170\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2034 - val_loss: 0.2818\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2380 - val_loss: 0.3514\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2032 - val_loss: 0.7267\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2222 - val_loss: 0.4410\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2108 - val_loss: 1.5535\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2105 - val_loss: 0.4748\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2361 - val_loss: 0.2565\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2135 - val_loss: 4.1016\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2502 - val_loss: 0.5748\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2293 - val_loss: 0.3606\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2466 - val_loss: 0.2722\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2203 - val_loss: 0.2596\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2113 - val_loss: 0.6870\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.1937 - val_loss: 0.3795\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2481 - val_loss: 0.6314\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1905 - val_loss: 1.1856\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2160 - val_loss: 0.2888\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.1910 - val_loss: 0.2305\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2426 - val_loss: 0.6034\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.1925 - val_loss: 0.2884\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2206 - val_loss: 0.4578\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2622 - val_loss: 2.0794\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2217 - val_loss: 0.9220\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2304 - val_loss: 1.1959\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2012 - val_loss: 0.2153\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2135 - val_loss: 0.6688\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2416 - val_loss: 0.3601\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2141 - val_loss: 0.7255\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2361 - val_loss: 2.5574\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2317 - val_loss: 0.1998\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2168 - val_loss: 1.0670\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2077 - val_loss: 0.5881\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2141 - val_loss: 1.4566\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2009 - val_loss: 0.5145\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1857 - val_loss: 0.2601\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2178 - val_loss: 0.7741\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1950 - val_loss: 1.6848\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2255 - val_loss: 0.2637\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2276 - val_loss: 0.2913\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2142 - val_loss: 1.2995\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2182 - val_loss: 0.3671\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1850 - val_loss: 0.8367\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2085 - val_loss: 0.4547\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2193 - val_loss: 0.5608\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2074 - val_loss: 0.3540\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2296 - val_loss: 1.2152\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2019 - val_loss: 1.1144\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2003 - val_loss: 0.3881\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2424 - val_loss: 0.2367\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2164 - val_loss: 0.4438\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2184 - val_loss: 0.3652\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1949 - val_loss: 1.0228\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2180 - val_loss: 1.1894\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1844 - val_loss: 0.5237\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2084 - val_loss: 0.2500\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.1967 - val_loss: 0.2949\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1955 - val_loss: 1.0869\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1939 - val_loss: 0.2626\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1981 - val_loss: 1.3365\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.2092 - val_loss: 0.5751\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.2082 - val_loss: 0.3183\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.2067 - val_loss: 2.6571\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2406 - val_loss: 0.8512\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.2082 - val_loss: 2.6244\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2337 - val_loss: 0.8047\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2556 - val_loss: 1.2103\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1985 - val_loss: 0.3572\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2109 - val_loss: 0.9328\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1822 - val_loss: 0.2572\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2222 - val_loss: 0.2160\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1913 - val_loss: 0.1870\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2232 - val_loss: 0.2673\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2046 - val_loss: 1.3059\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2114 - val_loss: 0.4959\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2133 - val_loss: 0.4927\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2096 - val_loss: 0.3615\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1939 - val_loss: 1.0504\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2197 - val_loss: 0.4132\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1972 - val_loss: 1.4232\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1847 - val_loss: 0.9514\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2071 - val_loss: 0.9941\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2181 - val_loss: 2.5346\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2017 - val_loss: 0.2089\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1815 - val_loss: 0.2134\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2164 - val_loss: 0.2268\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2085 - val_loss: 0.6989\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2214 - val_loss: 0.2713\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2277 - val_loss: 0.5587\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2174 - val_loss: 0.8692\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1975 - val_loss: 0.2438\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2300 - val_loss: 0.2672\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2035 - val_loss: 0.9151\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1653 - val_loss: 1.6405\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2053 - val_loss: 0.9322\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2042 - val_loss: 0.2792\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2230 - val_loss: 1.6945\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2195 - val_loss: 0.5183\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1844 - val_loss: 2.0044\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2234 - val_loss: 2.1431\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1960 - val_loss: 0.5840\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2287 - val_loss: 0.3023\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1786 - val_loss: 3.9174\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1939 - val_loss: 0.1984\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2034 - val_loss: 0.5145\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2212 - val_loss: 1.7198\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1840 - val_loss: 0.2340\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2331 - val_loss: 0.1719\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2082 - val_loss: 0.2556\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2060 - val_loss: 0.4524\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2261 - val_loss: 1.7390\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2144 - val_loss: 0.2751\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2105 - val_loss: 0.8681\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2290 - val_loss: 1.8250\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2172 - val_loss: 3.8681\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2313 - val_loss: 2.1300\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2292 - val_loss: 0.2245\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2254 - val_loss: 0.2735\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2073 - val_loss: 0.2897\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2075 - val_loss: 0.2477\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2193 - val_loss: 0.9623\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2182 - val_loss: 0.4439\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2302 - val_loss: 0.2031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2084 - val_loss: 0.4427\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2166 - val_loss: 0.2830\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2454 - val_loss: 2.1151\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2088 - val_loss: 0.5784\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2440 - val_loss: 0.5873\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2048 - val_loss: 0.2722\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2527 - val_loss: 1.1996\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2459 - val_loss: 0.4954\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2424 - val_loss: 0.4933\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2036 - val_loss: 0.6920\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1910 - val_loss: 0.2478\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2060 - val_loss: 0.4035\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2259 - val_loss: 0.4543\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1914 - val_loss: 0.4017\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2302 - val_loss: 0.2835\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1801 - val_loss: 0.3007\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1786 - val_loss: 0.4552\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2006 - val_loss: 0.5973\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1850 - val_loss: 1.1882\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.1857 - val_loss: 0.4906\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.2144 - val_loss: 0.8639\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1919 - val_loss: 0.3075\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2145 - val_loss: 0.6522\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2565 - val_loss: 0.8567\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2178 - val_loss: 1.5760\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2188 - val_loss: 0.4544\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2357 - val_loss: 0.5935\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2121 - val_loss: 0.4895\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2055 - val_loss: 0.6086\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1967 - val_loss: 3.0988\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2175 - val_loss: 0.2066\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2386 - val_loss: 0.2656\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2487 - val_loss: 0.3401\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2417 - val_loss: 0.2414\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1986 - val_loss: 1.6436\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2099 - val_loss: 1.7079\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2242 - val_loss: 2.6377\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1850 - val_loss: 0.1657\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.2243 - val_loss: 0.2277\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.2324 - val_loss: 0.8573\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.1985 - val_loss: 0.3344\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.1911 - val_loss: 1.2833\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2198 - val_loss: 0.5960\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2265 - val_loss: 0.2715\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2147 - val_loss: 0.4102\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1992 - val_loss: 2.8441\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1705 - val_loss: 0.2041\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2288 - val_loss: 0.2738\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1933 - val_loss: 0.2246\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2132 - val_loss: 0.3550\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1889 - val_loss: 0.4491\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2184 - val_loss: 0.3239\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2027 - val_loss: 0.2390\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2075 - val_loss: 0.1721\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1941 - val_loss: 0.2031\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2269 - val_loss: 2.3869\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2177 - val_loss: 0.3134\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2363 - val_loss: 0.6122\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2092 - val_loss: 0.2947\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2730 - val_loss: 0.7962\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1968 - val_loss: 0.3913\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2393 - val_loss: 1.2530\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2328 - val_loss: 2.6970\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2347 - val_loss: 2.3892\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2173 - val_loss: 0.6365\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2191 - val_loss: 0.5999\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2176 - val_loss: 0.4079\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2264 - val_loss: 1.6616\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2267 - val_loss: 0.2897\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2415 - val_loss: 0.2084\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1948 - val_loss: 0.8426\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2396 - val_loss: 0.3108\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2189 - val_loss: 1.0646\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2193 - val_loss: 0.3071\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2197 - val_loss: 0.3441\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2217 - val_loss: 1.5293\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1974 - val_loss: 0.9143\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2122 - val_loss: 1.1359\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1961 - val_loss: 0.2950\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2234 - val_loss: 0.4680\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2013 - val_loss: 1.4244\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2195 - val_loss: 0.3101\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.2082 - val_loss: 0.9025\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2181 - val_loss: 0.4547\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2035 - val_loss: 0.4055\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1982 - val_loss: 0.6393\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2112 - val_loss: 0.3597\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1809 - val_loss: 0.2420\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1787 - val_loss: 2.0539\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1967 - val_loss: 1.0207\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2392 - val_loss: 0.7780\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2046 - val_loss: 0.3366\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2064 - val_loss: 0.5321\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1986 - val_loss: 1.7707\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1995 - val_loss: 1.1343\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1805 - val_loss: 1.1368\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2023 - val_loss: 0.4146\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.1932 - val_loss: 0.4232\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.2289 - val_loss: 0.9240\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1854 - val_loss: 0.4941\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.2055 - val_loss: 0.7429\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.2139 - val_loss: 0.7991\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2032 - val_loss: 0.2445\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2123 - val_loss: 0.5906\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1923 - val_loss: 1.6039\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1959 - val_loss: 0.2466\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1985 - val_loss: 1.0875\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1841 - val_loss: 0.2097\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.2575 - val_loss: 0.5241\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.1918 - val_loss: 0.8988\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.1965 - val_loss: 0.2235\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1980 - val_loss: 0.4150\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.1706 - val_loss: 0.3120\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.1954 - val_loss: 0.4274\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.2169 - val_loss: 1.8164\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.2716 - val_loss: 1.6858\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.1934 - val_loss: 0.2841\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2389 - val_loss: 0.6935\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2177 - val_loss: 1.0896\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.1887 - val_loss: 0.2911\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.1933 - val_loss: 0.2948\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2295 - val_loss: 0.3708\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2330 - val_loss: 0.6713\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2548 - val_loss: 0.5995\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.1967 - val_loss: 0.4120\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2141 - val_loss: 1.0607\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.1694 - val_loss: 0.9449\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2079 - val_loss: 2.6474\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2240 - val_loss: 0.4520\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2192 - val_loss: 0.3280\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2185 - val_loss: 0.5026\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2469 - val_loss: 0.4911\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2165 - val_loss: 0.6605\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2130 - val_loss: 0.3187\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2188 - val_loss: 0.5943\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2187 - val_loss: 1.1281\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2419 - val_loss: 2.0093\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2274 - val_loss: 0.3341\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2373 - val_loss: 0.2496\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1955 - val_loss: 0.3013\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1917 - val_loss: 0.4923\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2070 - val_loss: 0.5365\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1906 - val_loss: 3.3006\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2163 - val_loss: 0.6286\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1996 - val_loss: 0.3531\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1928 - val_loss: 0.6503\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2178 - val_loss: 3.3136\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2419 - val_loss: 0.6675\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2137 - val_loss: 0.8617\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2071 - val_loss: 0.4962\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2330 - val_loss: 0.1701\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.2523 - val_loss: 0.6768\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.1781 - val_loss: 3.7486\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2191 - val_loss: 1.3056\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2142 - val_loss: 0.3600\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1959 - val_loss: 0.3737\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2157 - val_loss: 1.2445\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2071 - val_loss: 0.2421\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2083 - val_loss: 1.7317\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2207 - val_loss: 3.4392\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2461 - val_loss: 0.5738\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2103 - val_loss: 0.2156\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1978 - val_loss: 2.0226\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2149 - val_loss: 0.3751\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1942 - val_loss: 1.0034\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.1895 - val_loss: 4.3999\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.1974 - val_loss: 0.5334\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2137 - val_loss: 0.7468\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1950 - val_loss: 0.5020\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2000 - val_loss: 0.8323\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2132 - val_loss: 0.8136\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2417 - val_loss: 0.2341\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2061 - val_loss: 0.3252\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1826 - val_loss: 0.1473\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1939 - val_loss: 0.1700\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.2153 - val_loss: 0.2202\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.2015 - val_loss: 0.2278\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.2012 - val_loss: 0.3765\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.2217 - val_loss: 1.8704\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.2058 - val_loss: 0.2226\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.2152 - val_loss: 0.9433\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.2239 - val_loss: 0.6520\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.2118 - val_loss: 0.7355\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.2265 - val_loss: 0.2104\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.2253 - val_loss: 2.7837\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.1994 - val_loss: 0.3588\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.2053 - val_loss: 2.3793\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1921 - val_loss: 0.4326\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1725 - val_loss: 0.2385\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1817 - val_loss: 0.2300\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2501 - val_loss: 0.2650\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2032 - val_loss: 0.1657\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2062 - val_loss: 0.3371\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1964 - val_loss: 0.3800\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1914 - val_loss: 0.2793\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.1666 - val_loss: 0.5107\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2003 - val_loss: 0.2312\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2150 - val_loss: 2.3996\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2386 - val_loss: 0.5818\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2487 - val_loss: 1.1624\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1834 - val_loss: 0.2804\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2034 - val_loss: 0.2208\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1951 - val_loss: 0.6569\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2137 - val_loss: 0.2609\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1840 - val_loss: 0.1960\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2257 - val_loss: 0.4072\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2214 - val_loss: 0.2296\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2450 - val_loss: 0.5858\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2031 - val_loss: 0.3241\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2087 - val_loss: 0.2986\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.2172 - val_loss: 0.4503\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.2439 - val_loss: 1.0859\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.2011 - val_loss: 0.6045\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.1860 - val_loss: 0.2176\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.2111 - val_loss: 0.7504\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.2024 - val_loss: 0.5263\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.1805 - val_loss: 4.0026\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.2233 - val_loss: 1.2176\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2058 - val_loss: 0.3953\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2006 - val_loss: 0.2263\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2020 - val_loss: 1.8323\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1841 - val_loss: 0.4430\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2081 - val_loss: 0.8883\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1858 - val_loss: 0.2122\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.1991 - val_loss: 4.2641\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1942 - val_loss: 0.4516\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1872 - val_loss: 1.1521\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1908 - val_loss: 0.8293\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2047 - val_loss: 0.1966\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2181 - val_loss: 0.5100\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2343 - val_loss: 0.2121\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2146 - val_loss: 0.4821\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1841 - val_loss: 0.7146\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2332 - val_loss: 0.6874\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2281 - val_loss: 0.7023\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2138 - val_loss: 0.3016\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2241 - val_loss: 0.2864\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2260 - val_loss: 0.7389\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1893 - val_loss: 0.2311\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2353 - val_loss: 0.2154\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.1879 - val_loss: 0.3807\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2211 - val_loss: 0.3749\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2247 - val_loss: 0.8234\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2211 - val_loss: 1.7548\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2400 - val_loss: 0.9384\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1930 - val_loss: 0.2208\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.1867 - val_loss: 0.2916\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2046 - val_loss: 0.6310\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2001 - val_loss: 2.1986\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.1759 - val_loss: 0.6356\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.1929 - val_loss: 0.7703\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2394 - val_loss: 0.3914\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2195 - val_loss: 0.2586\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2173 - val_loss: 0.1810\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2079 - val_loss: 0.2956\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1957 - val_loss: 0.4147\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2267 - val_loss: 0.3282\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2049 - val_loss: 1.2626\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2188 - val_loss: 1.1703\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.1916 - val_loss: 0.8498\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1998 - val_loss: 0.7800\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.1939 - val_loss: 1.3461\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1746 - val_loss: 0.3619\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2220 - val_loss: 0.3736\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2184 - val_loss: 0.2163\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.2066 - val_loss: 0.4416\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.2315 - val_loss: 1.6355\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.2058 - val_loss: 0.4440\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.2138 - val_loss: 0.5593\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.2019 - val_loss: 0.4813\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.1791 - val_loss: 0.6038\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2070 - val_loss: 0.3777\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1881 - val_loss: 0.3095\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1895 - val_loss: 0.8077\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2007 - val_loss: 0.1793\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1864 - val_loss: 0.2113\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1858 - val_loss: 0.2661\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.1927 - val_loss: 0.2224\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1940 - val_loss: 0.3752\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2249 - val_loss: 1.7637\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1744 - val_loss: 0.7463\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1989 - val_loss: 0.4226\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1899 - val_loss: 0.3512\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1955 - val_loss: 0.3605\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.2410 - val_loss: 0.2054\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.2100 - val_loss: 0.2565\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.1987 - val_loss: 0.3133\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1889 - val_loss: 0.2577\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.1787 - val_loss: 0.9518\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2025 - val_loss: 0.5413\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1772 - val_loss: 1.4278\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2171 - val_loss: 0.2295\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2018 - val_loss: 0.4532\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2107 - val_loss: 0.4798\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2237 - val_loss: 2.9769\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2075 - val_loss: 0.2337\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1985 - val_loss: 1.4342\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2082 - val_loss: 0.9963\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2213 - val_loss: 0.3027\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2020 - val_loss: 1.0267\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2037 - val_loss: 0.4283\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.2023 - val_loss: 0.5591\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2046 - val_loss: 0.1895\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2089 - val_loss: 0.8334\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1975 - val_loss: 0.3179\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1984 - val_loss: 0.2722\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2040 - val_loss: 0.2132\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1862 - val_loss: 1.5974\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2266 - val_loss: 0.9826\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1969 - val_loss: 0.3159\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1939 - val_loss: 1.9737\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1887 - val_loss: 0.2238\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1872 - val_loss: 0.6689\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2164 - val_loss: 0.3211\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2036 - val_loss: 0.2189\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1985 - val_loss: 1.0869\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2104 - val_loss: 0.4622\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1855 - val_loss: 0.2454\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1960 - val_loss: 1.7838\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2145 - val_loss: 0.4317\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2165 - val_loss: 1.4742\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2098 - val_loss: 0.4924\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1991 - val_loss: 0.6802\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2111 - val_loss: 1.6645\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2095 - val_loss: 0.3120\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1938 - val_loss: 0.3179\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1631 - val_loss: 0.2382\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2127 - val_loss: 0.2991\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2288 - val_loss: 0.2391\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1971 - val_loss: 0.4244\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2358 - val_loss: 1.6206\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.2227 - val_loss: 0.9132\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.2035 - val_loss: 0.3994\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.2127 - val_loss: 1.8648\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.2181 - val_loss: 0.3775\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.2008 - val_loss: 0.4791\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.2375 - val_loss: 0.8504\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.2356 - val_loss: 0.4612\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2075 - val_loss: 0.1930\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1922 - val_loss: 1.2775\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2238 - val_loss: 0.3914\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1758 - val_loss: 0.5297\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1861 - val_loss: 0.1861\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2319 - val_loss: 0.8552\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1885 - val_loss: 0.5448\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2162 - val_loss: 0.3576\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1973 - val_loss: 0.2732\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1785 - val_loss: 1.7817\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1914 - val_loss: 0.4670\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2016 - val_loss: 0.3842\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2052 - val_loss: 2.1651\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2013 - val_loss: 0.3491\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2041 - val_loss: 0.4186\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2057 - val_loss: 0.2927\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2113 - val_loss: 0.8367\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1786 - val_loss: 0.2844\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1881 - val_loss: 0.8581\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1743 - val_loss: 2.1820\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2144 - val_loss: 0.5689\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2176 - val_loss: 1.0301\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2261 - val_loss: 1.7216\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1832 - val_loss: 0.3478\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1829 - val_loss: 1.8935\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.1974 - val_loss: 0.3996\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1975 - val_loss: 4.4611\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1936 - val_loss: 0.2446\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2353 - val_loss: 0.3056\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2107 - val_loss: 0.3527\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2120 - val_loss: 3.8986\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2011 - val_loss: 1.1003\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2678 - val_loss: 0.3958\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1966 - val_loss: 0.2889\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2187 - val_loss: 0.4837\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2327 - val_loss: 1.8964\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2043 - val_loss: 0.5499\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2277 - val_loss: 0.3956\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1862 - val_loss: 2.7808\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2104 - val_loss: 0.2995\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2372 - val_loss: 0.8729\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1925 - val_loss: 0.2790\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2052 - val_loss: 2.1450\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.2053 - val_loss: 1.1752\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1887 - val_loss: 0.4307\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2065 - val_loss: 0.7535\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1790 - val_loss: 0.4513\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2029 - val_loss: 0.3699\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1951 - val_loss: 0.9246\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2109 - val_loss: 0.6857\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1845 - val_loss: 0.2664\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2069 - val_loss: 0.3218\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2022 - val_loss: 0.7199\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1751 - val_loss: 0.3663\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1973 - val_loss: 0.7325\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1819 - val_loss: 0.3720\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2282 - val_loss: 1.1766\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1896 - val_loss: 0.2143\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2061 - val_loss: 0.2859\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2215 - val_loss: 3.3029\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2101 - val_loss: 0.4532\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1726 - val_loss: 0.4032\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2023 - val_loss: 0.2937\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2201 - val_loss: 0.3843\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2043 - val_loss: 0.1905\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1860 - val_loss: 0.2240\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2130 - val_loss: 0.5353\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2103 - val_loss: 0.3181\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1915 - val_loss: 0.5739\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1623 - val_loss: 0.9967\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1868 - val_loss: 0.2234\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2075 - val_loss: 0.5920\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2061 - val_loss: 0.4893\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1972 - val_loss: 0.2167\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2006 - val_loss: 0.3195\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2086 - val_loss: 0.4706\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2016 - val_loss: 0.5059\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2330 - val_loss: 1.2083\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2061 - val_loss: 0.1961\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2238 - val_loss: 0.8377\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2039 - val_loss: 0.5517\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2044 - val_loss: 1.0136\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2204 - val_loss: 0.9701\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2209 - val_loss: 2.8038\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1887 - val_loss: 0.3107\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1989 - val_loss: 1.1986\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.2010 - val_loss: 0.4246\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.2082 - val_loss: 0.2553\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.2088 - val_loss: 0.9107\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.2211 - val_loss: 0.5013\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.1932 - val_loss: 0.5412\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1737 - val_loss: 0.3201\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1974 - val_loss: 0.5270\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2310 - val_loss: 1.1142\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1794 - val_loss: 0.3451\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2175 - val_loss: 0.2497\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2110 - val_loss: 0.2249\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1941 - val_loss: 0.3682\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1834 - val_loss: 0.1730\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1855 - val_loss: 0.3600\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2035 - val_loss: 0.4995\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2133 - val_loss: 0.2926\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2191 - val_loss: 0.2228\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2161 - val_loss: 1.6326\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1832 - val_loss: 3.5712\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2135 - val_loss: 2.7659\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2096 - val_loss: 0.3670\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1860 - val_loss: 0.3721\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2113 - val_loss: 0.4451\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1902 - val_loss: 0.2988\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1817 - val_loss: 0.6153\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1774 - val_loss: 0.4817\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1838 - val_loss: 0.6701\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1980 - val_loss: 0.9353\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2209 - val_loss: 1.7349\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1853 - val_loss: 0.6081\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2121 - val_loss: 1.7521\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2104 - val_loss: 0.6234\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2044 - val_loss: 0.1811\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2090 - val_loss: 1.1067\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1766 - val_loss: 0.4047\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2224 - val_loss: 1.0794\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2074 - val_loss: 1.1476\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1985 - val_loss: 1.9535\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1834 - val_loss: 0.3949\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1929 - val_loss: 2.9414\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2215 - val_loss: 0.3691\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1973 - val_loss: 0.6060\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2190 - val_loss: 0.6560\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1853 - val_loss: 0.2687\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2105 - val_loss: 3.0948\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2419 - val_loss: 0.9103\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1851 - val_loss: 0.4834\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2185 - val_loss: 0.6551\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1708 - val_loss: 0.2951\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2198 - val_loss: 0.2678\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2168 - val_loss: 0.5103\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2055 - val_loss: 0.5238\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2158 - val_loss: 0.6539\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2035 - val_loss: 0.9019\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2003 - val_loss: 0.5348\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2019 - val_loss: 4.4383\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2118 - val_loss: 0.4077\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2379 - val_loss: 0.4920\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1931 - val_loss: 0.4089\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1725 - val_loss: 1.1521\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1803 - val_loss: 5.5641\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2477 - val_loss: 0.7859\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2127 - val_loss: 0.4226\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2394 - val_loss: 0.3943\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2121 - val_loss: 1.8347\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2087 - val_loss: 3.4064\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.1779 - val_loss: 0.8014\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.1698 - val_loss: 3.5336\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.2432 - val_loss: 0.5048\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.1831 - val_loss: 1.2011\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1982 - val_loss: 0.4166\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2175 - val_loss: 0.4161\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2228 - val_loss: 0.4668\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1727 - val_loss: 0.4022\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2009 - val_loss: 0.2350\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2165 - val_loss: 0.2557\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.1719 - val_loss: 0.2101\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.2118 - val_loss: 0.2277\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.1909 - val_loss: 3.4578\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.2197 - val_loss: 0.8680\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.1897 - val_loss: 2.6700\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1889 - val_loss: 0.2072\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1837 - val_loss: 0.2217\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1862 - val_loss: 0.3763\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1806 - val_loss: 0.3232\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1825 - val_loss: 0.9698\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2189 - val_loss: 0.5660\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2019 - val_loss: 2.3016\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2242 - val_loss: 1.1908\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1929 - val_loss: 0.2464\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1893 - val_loss: 0.3664\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2034 - val_loss: 0.2040\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2082 - val_loss: 0.4659\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1970 - val_loss: 1.4314\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2060 - val_loss: 0.2805\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2312 - val_loss: 0.9935\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1952 - val_loss: 0.5704\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2485 - val_loss: 0.4255\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1994 - val_loss: 0.1958\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1779 - val_loss: 0.3741\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1800 - val_loss: 2.5710\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2234 - val_loss: 0.9140\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2292 - val_loss: 0.3301\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1887 - val_loss: 0.3986\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1993 - val_loss: 0.1700\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.1873 - val_loss: 0.1889\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.2032 - val_loss: 0.3902\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.2071 - val_loss: 0.3470\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.1848 - val_loss: 0.6280\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1623 - val_loss: 0.2027\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1956 - val_loss: 0.6353\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2008 - val_loss: 1.3302\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2021 - val_loss: 0.2303\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1905 - val_loss: 0.7202\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2345 - val_loss: 4.3788\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1993 - val_loss: 0.5584\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2126 - val_loss: 0.4984\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1807 - val_loss: 0.5134\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2097 - val_loss: 0.6426\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1992 - val_loss: 0.3349\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1781 - val_loss: 2.4927\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2165 - val_loss: 0.4414\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2197 - val_loss: 0.2361\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2258 - val_loss: 0.3159\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2166 - val_loss: 0.2606\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2376 - val_loss: 1.3475\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1976 - val_loss: 0.9968\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2410 - val_loss: 0.4665\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2166 - val_loss: 0.2417\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2307 - val_loss: 0.3178\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2316 - val_loss: 1.1917\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2410 - val_loss: 0.9993\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1812 - val_loss: 2.2461\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2120 - val_loss: 0.4398\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2260 - val_loss: 1.5129\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2487 - val_loss: 2.3618\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2055 - val_loss: 0.2715\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1901 - val_loss: 0.9893\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1800 - val_loss: 0.5012\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1794 - val_loss: 0.5515\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1959 - val_loss: 0.3387\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1933 - val_loss: 0.8229\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.2102 - val_loss: 3.7708\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2429 - val_loss: 0.2227\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2179 - val_loss: 1.4099\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1949 - val_loss: 0.2566\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1756 - val_loss: 1.3861\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2092 - val_loss: 1.0033\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1969 - val_loss: 0.2197\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2373 - val_loss: 0.3746\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1797 - val_loss: 0.9767\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2017 - val_loss: 0.4440\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.1896 - val_loss: 1.9708\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.2176 - val_loss: 0.2392\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.2031 - val_loss: 1.6408\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.1940 - val_loss: 1.0069\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.2144 - val_loss: 1.8933\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.2017 - val_loss: 0.3573\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.1976 - val_loss: 0.6787\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.1847 - val_loss: 4.6575\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.2208 - val_loss: 0.4212\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.2312 - val_loss: 0.2102\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.1807 - val_loss: 1.7056\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.2360 - val_loss: 0.9339\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.2145 - val_loss: 4.6131\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2092 - val_loss: 0.2373\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1739 - val_loss: 0.2055\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1532 - val_loss: 3.2334\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2041 - val_loss: 1.3523\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2108 - val_loss: 0.4553\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2061 - val_loss: 0.3405\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2244 - val_loss: 0.1828\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2075 - val_loss: 0.2326\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2022 - val_loss: 2.8126\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2213 - val_loss: 0.3773\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1756 - val_loss: 0.3323\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2017 - val_loss: 0.2204\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2042 - val_loss: 0.6992\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1879 - val_loss: 0.3135\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2382 - val_loss: 2.2431\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2202 - val_loss: 1.1731\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2165 - val_loss: 1.7402\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2099 - val_loss: 0.2719\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2352 - val_loss: 0.5189\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2402 - val_loss: 0.4295\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2154 - val_loss: 4.7072\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1896 - val_loss: 1.1999\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2037 - val_loss: 0.2097\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1830 - val_loss: 1.3383\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1719 - val_loss: 2.3025\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2003 - val_loss: 0.2065\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1819 - val_loss: 0.2036\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1916 - val_loss: 0.2726\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1619 - val_loss: 0.2781\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2150 - val_loss: 0.4269\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1828 - val_loss: 1.7115\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1945 - val_loss: 1.4570\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1591 - val_loss: 0.5110\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2050 - val_loss: 2.4800\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1968 - val_loss: 1.4523\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2167 - val_loss: 0.4468\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2175 - val_loss: 0.8086\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1894 - val_loss: 0.3331\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2142 - val_loss: 0.2689\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2017 - val_loss: 2.9856\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1882 - val_loss: 0.4075\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1577 - val_loss: 0.2409\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2250 - val_loss: 0.3221\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1643 - val_loss: 0.2773\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2161 - val_loss: 0.3400\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2172 - val_loss: 0.3088\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1647 - val_loss: 0.2635\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2078 - val_loss: 0.2620\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1898 - val_loss: 2.7959\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2113 - val_loss: 0.6045\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2203 - val_loss: 2.6953\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1939 - val_loss: 0.2074\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1983 - val_loss: 0.2966\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1868 - val_loss: 0.6356\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2516 - val_loss: 0.3542\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2093 - val_loss: 0.9482\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2164 - val_loss: 3.0474\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2071 - val_loss: 0.1828\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2310 - val_loss: 1.3731\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1987 - val_loss: 0.2274\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1942 - val_loss: 0.4872\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2076 - val_loss: 0.3320\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1748 - val_loss: 0.3438\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2125 - val_loss: 0.3166\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2223 - val_loss: 2.4044\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1998 - val_loss: 0.3011\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1888 - val_loss: 0.2060\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2164 - val_loss: 0.2530\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1963 - val_loss: 0.8523\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2004 - val_loss: 0.2150\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1961 - val_loss: 1.1860\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2242 - val_loss: 3.1633\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.1829 - val_loss: 0.2822\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.1707 - val_loss: 0.2537\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.1712 - val_loss: 1.5403\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.1924 - val_loss: 3.4799\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.2010 - val_loss: 1.0125\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.2081 - val_loss: 0.9416\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1726 - val_loss: 1.5100\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.1927 - val_loss: 0.4258\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.1966 - val_loss: 0.2405\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2349 - val_loss: 0.3905\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2035 - val_loss: 0.7981\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1842 - val_loss: 0.7721\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2096 - val_loss: 2.0461\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1952 - val_loss: 0.2629\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1775 - val_loss: 0.4457\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1863 - val_loss: 0.4893\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1780 - val_loss: 0.2530\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.1903 - val_loss: 0.2941\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1870 - val_loss: 0.4407\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2198 - val_loss: 0.3215\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1846 - val_loss: 0.4241\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2018 - val_loss: 0.3406\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1708 - val_loss: 1.0930\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2001 - val_loss: 0.2047\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1923 - val_loss: 0.6952\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1856 - val_loss: 0.4209\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1964 - val_loss: 3.4332\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1912 - val_loss: 2.2326\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1869 - val_loss: 1.2045\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1996 - val_loss: 1.4685\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2190 - val_loss: 2.2549\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2401 - val_loss: 2.3472\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1896 - val_loss: 0.6744\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2152 - val_loss: 0.6269\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1739 - val_loss: 0.3805\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1738 - val_loss: 0.5688\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.1896 - val_loss: 0.3041\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.2073 - val_loss: 0.3599\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.2284 - val_loss: 1.4782\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.1880 - val_loss: 0.1809\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.1928 - val_loss: 0.8278\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.2065 - val_loss: 1.0436\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1827 - val_loss: 0.1802\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1960 - val_loss: 0.8419\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1789 - val_loss: 0.4304\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1938 - val_loss: 0.4575\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2181 - val_loss: 0.4741\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1984 - val_loss: 2.2501\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1915 - val_loss: 1.1505\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2034 - val_loss: 0.3243\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1818 - val_loss: 0.4994\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1697 - val_loss: 0.2964\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1830 - val_loss: 0.6815\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2027 - val_loss: 0.4411\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2109 - val_loss: 4.0080\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1859 - val_loss: 2.3034\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2000 - val_loss: 0.1864\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2193 - val_loss: 0.6022\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2162 - val_loss: 0.2954\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.1796 - val_loss: 0.4109\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1819 - val_loss: 0.2994\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1982 - val_loss: 0.4767\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1977 - val_loss: 0.7986\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1712 - val_loss: 0.2659\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1911 - val_loss: 0.4707\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2013 - val_loss: 1.1731\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2153 - val_loss: 0.1969\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2033 - val_loss: 0.5987\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2155 - val_loss: 0.2563\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2131 - val_loss: 4.2965\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2022 - val_loss: 0.5892\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1887 - val_loss: 0.2335\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1816 - val_loss: 0.8480\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1844 - val_loss: 1.2174\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2018 - val_loss: 1.5634\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2087 - val_loss: 0.3584\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2317 - val_loss: 0.1568\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2220 - val_loss: 0.6245\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1931 - val_loss: 0.5103\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2058 - val_loss: 0.8022\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.1807 - val_loss: 0.2473\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2315 - val_loss: 0.2547\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.2102 - val_loss: 2.4577\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.2064 - val_loss: 0.3179\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1998 - val_loss: 0.1991\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1805 - val_loss: 0.6582\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2019 - val_loss: 0.4786\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1848 - val_loss: 0.2196\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2308 - val_loss: 0.4566\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2360 - val_loss: 3.8292\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1996 - val_loss: 0.2893\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1911 - val_loss: 1.0939\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1874 - val_loss: 0.8499\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1684 - val_loss: 0.2510\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2115 - val_loss: 0.2349\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1752 - val_loss: 0.1782\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2210 - val_loss: 1.7251\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1916 - val_loss: 0.2741\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2221 - val_loss: 0.2559\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2138 - val_loss: 0.5040\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2143 - val_loss: 0.6230\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1910 - val_loss: 0.3561\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.1858 - val_loss: 0.2604\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1766 - val_loss: 0.4844\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2176 - val_loss: 0.2866\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2467 - val_loss: 2.6021\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2081 - val_loss: 0.5167\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1823 - val_loss: 0.2168\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.2147 - val_loss: 0.5619\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.1914 - val_loss: 0.3576\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.1909 - val_loss: 0.9614\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.1820 - val_loss: 0.3599\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1753 - val_loss: 0.7183\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1892 - val_loss: 0.2582\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1843 - val_loss: 0.1822\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1688 - val_loss: 0.2274\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.1797 - val_loss: 0.2591\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.1916 - val_loss: 0.5041\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.1954 - val_loss: 0.2402\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.2057 - val_loss: 1.3369\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.1759 - val_loss: 0.4020\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.1906 - val_loss: 0.4051\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1908 - val_loss: 1.3045\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1779 - val_loss: 0.4032\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1966 - val_loss: 0.3926\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2035 - val_loss: 0.7514\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1674 - val_loss: 0.6427\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1911 - val_loss: 0.1779\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1907 - val_loss: 0.2993\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1854 - val_loss: 0.6645\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1899 - val_loss: 0.5956\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1863 - val_loss: 0.2141\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1896 - val_loss: 0.1797\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1739 - val_loss: 0.1656\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2135 - val_loss: 0.8388\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2249 - val_loss: 0.5392\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1971 - val_loss: 1.2128\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1868 - val_loss: 0.3165\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2158 - val_loss: 0.1989\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1645 - val_loss: 0.4477\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2078 - val_loss: 1.8318\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1686 - val_loss: 0.7752\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1808 - val_loss: 0.2724\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1795 - val_loss: 1.1889\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2030 - val_loss: 0.2562\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1564 - val_loss: 1.2201\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1832 - val_loss: 0.5743\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2271 - val_loss: 0.4650\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2502 - val_loss: 0.6453\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1777 - val_loss: 0.2181\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1885 - val_loss: 1.0290\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2275 - val_loss: 0.6339\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2105 - val_loss: 0.5519\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1747 - val_loss: 0.2717\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1633 - val_loss: 0.7360\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1648 - val_loss: 0.4887\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2116 - val_loss: 3.3667\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2006 - val_loss: 0.6833\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1843 - val_loss: 0.1872\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2384 - val_loss: 0.3709\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2164 - val_loss: 0.4388\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1959 - val_loss: 0.3930\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2294 - val_loss: 2.3413\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1813 - val_loss: 0.3394\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1814 - val_loss: 1.1133\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2022 - val_loss: 0.4817\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1996 - val_loss: 1.9072\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1969 - val_loss: 1.2532\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1972 - val_loss: 0.4965\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2179 - val_loss: 0.2012\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1846 - val_loss: 1.4096\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1875 - val_loss: 0.5364\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1699 - val_loss: 0.4168\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.1973 - val_loss: 0.9773\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.1973 - val_loss: 0.9588\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.1755 - val_loss: 0.2290\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.1642 - val_loss: 0.3884\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.2244 - val_loss: 0.3134\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.2148 - val_loss: 1.1786\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.2093 - val_loss: 0.3415\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.2033 - val_loss: 0.3351\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.1916 - val_loss: 0.6077\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.2083 - val_loss: 2.4300\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.1753 - val_loss: 0.6178\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.1978 - val_loss: 0.2249\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.1705 - val_loss: 0.2116\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.2152 - val_loss: 1.0924\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.1755 - val_loss: 0.4999\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1888 - val_loss: 0.4738\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1787 - val_loss: 1.8257\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2095 - val_loss: 0.2724\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1800 - val_loss: 1.6997\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2008 - val_loss: 1.9745\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1994 - val_loss: 0.8445\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2049 - val_loss: 0.4032\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1846 - val_loss: 0.7293\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1845 - val_loss: 3.2677\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1916 - val_loss: 0.5580\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2106 - val_loss: 0.2080\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2063 - val_loss: 0.3093\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2079 - val_loss: 0.3264\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1976 - val_loss: 0.3860\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2007 - val_loss: 0.2871\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1724 - val_loss: 0.9795\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2180 - val_loss: 0.9168\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1836 - val_loss: 0.9912\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1830 - val_loss: 0.6131\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1984 - val_loss: 0.4361\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1885 - val_loss: 0.2392\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2030 - val_loss: 0.3935\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1670 - val_loss: 0.4555\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1772 - val_loss: 0.3702\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1682 - val_loss: 1.9792\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2075 - val_loss: 0.4221\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1921 - val_loss: 0.2694\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1621 - val_loss: 0.2198\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1681 - val_loss: 3.5078\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1769 - val_loss: 1.5836\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2169 - val_loss: 0.2016\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1763 - val_loss: 0.2085\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1949 - val_loss: 0.2950\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1865 - val_loss: 0.3465\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1848 - val_loss: 0.5557\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2121 - val_loss: 0.4588\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1910 - val_loss: 0.2248\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2294 - val_loss: 2.6577\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1833 - val_loss: 0.3197\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1942 - val_loss: 0.5529\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1920 - val_loss: 0.2196\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1812 - val_loss: 0.6329\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1977 - val_loss: 0.2125\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1984 - val_loss: 0.4471\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2035 - val_loss: 0.2753\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1923 - val_loss: 2.2542\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1936 - val_loss: 3.3668\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1932 - val_loss: 0.3247\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1799 - val_loss: 0.2162\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2032 - val_loss: 0.7251\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1966 - val_loss: 0.5123\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1706 - val_loss: 0.2400\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1662 - val_loss: 1.7365\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1835 - val_loss: 1.2114\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2102 - val_loss: 0.3923\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.2037 - val_loss: 0.2760\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.2054 - val_loss: 0.7541\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.1840 - val_loss: 1.6600\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.1958 - val_loss: 0.5333\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.1919 - val_loss: 5.4488\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.1938 - val_loss: 0.2123\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.1972 - val_loss: 1.0261\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.1590 - val_loss: 1.8359\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.1693 - val_loss: 0.1955\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.1774 - val_loss: 0.3420\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.1912 - val_loss: 0.2913\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.1933 - val_loss: 0.2181\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.1760 - val_loss: 0.4631\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.1969 - val_loss: 0.2647\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.1529 - val_loss: 4.0356\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1718 - val_loss: 0.2960\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2051 - val_loss: 2.6475\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1992 - val_loss: 0.6535\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2066 - val_loss: 0.3632\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1795 - val_loss: 1.0173\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.1938 - val_loss: 0.2529\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.1784 - val_loss: 0.1836\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.2182 - val_loss: 0.4966\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.1809 - val_loss: 0.3106\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.1864 - val_loss: 0.3296\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.1818 - val_loss: 0.4608\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.2016 - val_loss: 0.7538\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.1974 - val_loss: 0.2589\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1786 - val_loss: 0.1622\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1961 - val_loss: 0.2446\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2246 - val_loss: 6.1004\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1898 - val_loss: 1.8771\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1714 - val_loss: 0.3155\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1983 - val_loss: 0.4883\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.2027 - val_loss: 1.5364\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.1979 - val_loss: 0.2692\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.2024 - val_loss: 0.9738\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.1846 - val_loss: 0.3728\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.2251 - val_loss: 1.1896\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.1708 - val_loss: 4.8182\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.1883 - val_loss: 0.2823\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.2238 - val_loss: 0.5017\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.2016 - val_loss: 0.2912\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.2154 - val_loss: 0.6779\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.1565 - val_loss: 1.6103\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.2000 - val_loss: 0.2371\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.2162 - val_loss: 0.2579\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.2156 - val_loss: 0.3505\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.1762 - val_loss: 0.2537\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.2190 - val_loss: 1.9045\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.2064 - val_loss: 1.9171\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.2012 - val_loss: 0.1700\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.2188 - val_loss: 0.2801\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.2133 - val_loss: 0.2926\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.1865 - val_loss: 1.2637\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.2082 - val_loss: 0.4832\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.2137 - val_loss: 0.2050\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1928 - val_loss: 0.3576\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1822 - val_loss: 0.3310\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1865 - val_loss: 0.2503\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1752 - val_loss: 0.4928\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2031 - val_loss: 0.1995\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1861 - val_loss: 0.4684\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1629 - val_loss: 0.2852\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1957 - val_loss: 1.3692\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1918 - val_loss: 1.0453\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.1821 - val_loss: 0.3146\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.1806 - val_loss: 0.7807\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.2077 - val_loss: 1.5517\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1743 - val_loss: 2.0570\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1792 - val_loss: 0.1962\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1904 - val_loss: 1.1949\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1885 - val_loss: 0.1939\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2103 - val_loss: 2.8836\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1605 - val_loss: 0.2032\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1859 - val_loss: 0.3687\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1908 - val_loss: 0.6484\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1966 - val_loss: 0.2738\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1922 - val_loss: 0.5470\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2186 - val_loss: 1.2088\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1925 - val_loss: 1.8113\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2016 - val_loss: 1.1891\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1660 - val_loss: 0.2236\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2020 - val_loss: 0.3670\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1882 - val_loss: 1.1673\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.2125 - val_loss: 0.5814\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.1865 - val_loss: 0.2352\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.2428 - val_loss: 0.8982\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.2049 - val_loss: 0.3518\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.1952 - val_loss: 1.1199\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.2118 - val_loss: 0.6896\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.1912 - val_loss: 0.2541\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.1967 - val_loss: 0.3674\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1945 - val_loss: 1.2519\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2036 - val_loss: 0.4425\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1794 - val_loss: 2.2231\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1893 - val_loss: 0.6938\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1894 - val_loss: 0.4350\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1970 - val_loss: 0.5386\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1757 - val_loss: 0.5350\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.1588 - val_loss: 0.2153\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.1781 - val_loss: 0.4234\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.1561 - val_loss: 0.4248\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.2033 - val_loss: 0.4719\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2363 - val_loss: 1.0113\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2010 - val_loss: 0.5040\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2110 - val_loss: 0.9039\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2241 - val_loss: 0.2607\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1922 - val_loss: 1.0474\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2050 - val_loss: 0.2984\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1807 - val_loss: 0.3394\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1847 - val_loss: 0.2351\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1589 - val_loss: 0.2050\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.2338 - val_loss: 0.7162\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1996 - val_loss: 0.7431\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1581 - val_loss: 0.7633\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1912 - val_loss: 1.6890\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1992 - val_loss: 0.5583\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1899 - val_loss: 1.6417\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2095 - val_loss: 0.2199\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1951 - val_loss: 3.9762\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2313 - val_loss: 0.3404\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1902 - val_loss: 0.3427\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1897 - val_loss: 0.2872\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.2139 - val_loss: 0.4987\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1978 - val_loss: 0.5146\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1941 - val_loss: 0.5011\n",
      "iTrain on 2680 samples, validate on 536 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1761 - val_loss: 0.2395\n"
     ]
    },
    {
     "ename": "InterruptException",
     "evalue": "InterruptException:",
     "output_type": "error",
     "traceback": [
      "InterruptException:",
      "",
      "Stacktrace:",
      " [1] RefValue at ./refvalue.jl:8 [inlined]",
      " [2] RefValue at ./refvalue.jl:10 [inlined]",
      " [3] Ref at ./refpointer.jl:94 [inlined]",
      " [4] CuTextureArray at /home/hastings/.julia/packages/CuTextures/VZ9IC/src/texturearray.jl:46 [inlined]",
      " [5] CuTextureArray at /home/hastings/.julia/packages/CuTextures/VZ9IC/src/texturearray.jl:72 [inlined]",
      " [6] CuTextureArray(::Array{Float32,3}) at /home/hastings/.julia/packages/CuTextures/VZ9IC/src/texturearray.jl:150",
      " [7] GPUItkImage(::ItkImage) at /media/data/hastings/ct-angledslice-align/ultrasoundgeneration.jl:49",
      " [8] generate_data(::Array{ItkImage,1}, ::Array{Array{Array{Float64,1},1},1}) at /media/data/hastings/ct-angledslice-align/ultrasoundgeneration.jl:166",
      " [9] top-level scope at In[29]:2"
     ]
    }
   ],
   "source": [
    "while true\n",
    "    data, classes = generate_data(\n",
    "        [x.image for x in annotated_images], \n",
    "        [x.annotation for x in annotated_images]\n",
    "    )\n",
    "    data = longcat(data)\n",
    "    classes = longcat(classes)\n",
    "    network_parallel.model.fit(\n",
    "        [data, copy(classes[:, 4:end])], copy(classes[:, 1:3]), batch_size=90, \n",
    "        verbose=2, validation_data=((tdata, copy(tclasses[:, 4:end])), copy(tclasses[:, 1:3]))\n",
    "    )\n",
    "    if rand() < .1\n",
    "        network_parallel.model.save(\"models/includeangle2\")\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while true\n",
    "    data, classes = generate_data(\n",
    "        [x.image for x in annotated_images], \n",
    "        [x.annotation for x in annotated_images]\n",
    "    )\n",
    "    network_parallel.model.fit(\n",
    "        longcat(data), longcat(classes), batch_size=64, \n",
    "        verbose=2, validation_data=(tdata, tclasses)\n",
    "    )\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "using BenchmarkTools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_parallel.model.compile(loss=network_parallel.keras.losses.mean_squared_error,\n",
    "              optimizer=network_parallel.Adam(lr=0.00005))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2.381736 seconds (5.91 M allocations: 2.022 GiB, 11.93% gc time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time [generate_sample(jimage, annotation) for _ = 1:7000]\n",
    "0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i  7.974665 seconds (2.49 M allocations: 11.854 GiB, 24.93% gc time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time data, classes = generate_data(\n",
    "    [x.image for x in annotated_images], \n",
    "    [x.annotation for x in annotated_images]\n",
    ")\n",
    "0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_parallel.model.fit(longcat(data), longcat(classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = network_parallel.model.predict((tdata, tclasses[:, 4:end]))\n",
    "0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2680Ã—6 Array{Float32,2}:\n",
       " -2.3612      2.98488    -0.317325   -0.312693     0.971511    -0.0364157 \n",
       " -3.77088    -1.1458      1.37392    -0.293181     0.209181    -0.0263561 \n",
       " -0.2158      2.821      -1.54949    -0.100725    -0.381574    -0.169062  \n",
       " -1.08362    -4.68368     4.19826     0.00426911   0.646132    -0.0348382 \n",
       "  2.9246      0.272539   -1.12352     0.109778    -0.25202     -0.144061  \n",
       " -5.16185     0.608053   -5.77216     0.0582806   -0.473698    -0.517308  \n",
       " -0.939647    2.52472     0.543708   -0.0467159    0.211801     0.218336  \n",
       " -0.680392   -0.952679   -0.0550417   0.351744    -0.4231       0.364508  \n",
       " -0.290873   -5.96941    -0.951299   -0.277362     1.07724      0.380513  \n",
       "  0.0115749  -4.87155     0.830851    0.688096     0.438346     0.0268029 \n",
       " -1.92966     4.93054    -3.08607    -0.563987     0.545114     0.31458   \n",
       " -1.04835    -0.700078   -0.284712    0.313875    -0.748442    -0.400176  \n",
       "  0.0277693  -2.45696    -4.82403     0.861593    -1.0333      -0.435484  \n",
       "  â‹®                                                             â‹®         \n",
       " -0.72766    -0.843287    2.43821    -0.154786    -0.463963     0.244591  \n",
       "  1.557      -3.82685    -1.51034     0.637418     0.0690035    0.0777535 \n",
       " -0.345315    2.22839    -0.371545   -0.221899    -0.178491     0.479271  \n",
       "  1.36377     0.0538939  -0.164778   -1.13887     -0.0472825    0.523512  \n",
       " -5.42898    -1.05815     0.386831    0.107086     0.0665522   -0.435782  \n",
       "  0.89548     2.30566     2.08583    -0.467655    -0.453827    -0.54144   \n",
       "  2.05414     1.96782    -0.385635    0.419602    -0.58407      0.187859  \n",
       " -0.215629   -0.884927    2.01896    -0.0652034   -0.00668126   0.16061   \n",
       "  2.37868     0.856226    1.55122    -0.143459    -0.675617    -0.0527091 \n",
       "  0.20718     0.279158   -2.22733     0.0209638    0.727201    -0.396706  \n",
       " -0.159285    2.3783     -1.16489    -0.931394     1.48734     -0.570732  \n",
       " -6.86336     1.4857      1.60241    -0.458362    -0.0406496    0.00924082"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data =  longcat(data)\n",
    "classes = longcat(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#network_parallel.model.save(\"models/juliatrain3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.0028841f0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tclasses[103]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "Figure(PyObject <Figure size 640x480 with 1 Axes>)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.197008"
     ]
    }
   ],
   "source": [
    "i += 1\n",
    "scatter(tclasses[:, i], predictions[:, i], s= 0.1)\n",
    "show()\n",
    "print(sum(tclasses[:, i] .- predictions[:, i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: data not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: data not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope at In[35]:1"
     ]
    }
   ],
   "source": [
    "imshow(data[1][:, :, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "Figure(PyObject <Figure size 640x480 with 1 Axes>)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "PyObject <matplotlib.image.AxesImage object at 0x0000001CA9F1F2E8>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imshow(data[1][:, :, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 32/536 [>.............................] - ETA: 42s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 64/536 [==>...........................] - ETA: 20s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "128/536 [======>.......................] - ETA: 9s \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "192/536 [=========>....................] - ETA: 5s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "256/536 [=============>................] - ETA: 3s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "320/536 [================>.............] - ETA: 2s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "384/536 [====================>.........] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "448/536 [========================>.....] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "512/536 [===========================>..] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "536/536 [==============================] - 4s 7ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.23950253471509733"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_parallel.model.evaluate((tdata, tclasses[:, 4:end]), tclasses[:, 1:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "536Ã—128Ã—128Ã—4 Array{Float32,4}:\n",
       "[:, :, 1, 1] =\n",
       " 0.0286113    0.0297012    0.0311875   â€¦   0.0335137    0.0334883 \n",
       " 0.0260898    0.0268984    0.0324648       0.0263516    0.0259883 \n",
       " 0.521023     0.520916     0.531498        0.482781     0.48134   \n",
       " 0.0692559    0.036418     0.0314961       0.521074     0.515477  \n",
       " 0.0258457    0.0232852    0.0205762       0.464072     0.458311  \n",
       " 0.0418652    0.0381738    0.0264707   â€¦   0.129314     0.0873496 \n",
       " 0.504076     0.503789     0.500543        0.666941     0.684818  \n",
       " 0.0291563    0.0338516    0.0303359       0.0739688    0.0744258 \n",
       " 0.445494     0.449293     0.452703        0.435586     0.444687  \n",
       " 0.0232676    0.0234414    0.0243652       0.551439     0.547307  \n",
       " 0.00511328   0.00514062   0.00619531  â€¦  -0.00717187  -0.00351562\n",
       " 0.528787     0.525613     0.529543        0.055668     0.0389219 \n",
       " 0.43409      0.370729     0.291846        0.0232324    0.022373  \n",
       " â‹®                                     â‹±                          \n",
       " 0.683465     0.640918     0.62525         0.521309     0.510756  \n",
       " 0.455008     0.45993      0.469602    â€¦   0.434732     0.435162  \n",
       " 0.443275     0.436172     0.444176        0.0756523    0.0674512 \n",
       " 0.456658     0.456389     0.45426         0.446271     0.443875  \n",
       " 0.48448      0.490293     0.487471        0.451436     0.443021  \n",
       " 0.454908     0.457607     0.457576        0.0405801    0.0552813 \n",
       " 0.462119     0.456971     0.452025    â€¦   0.442336     0.43267   \n",
       " 0.458102     0.450801     0.449576        0.516297     0.522111  \n",
       " 0.522371     0.527699     0.532201        0.453143     0.456893  \n",
       " 0.522375     0.526643     0.536777        0.455791     0.447313  \n",
       " 0.00564063  -0.00156445  -0.00117578      0.0027793   -0.00304492\n",
       " 0.447627     0.444361     0.448891    â€¦   0.459143     0.465395  \n",
       "\n",
       "[:, :, 2, 1] =\n",
       " 0.0301934    0.032123     0.0325215   â€¦   0.0308418     0.0355566 \n",
       " 0.0328418    0.0351445    0.0339492       0.0229434     0.0252949 \n",
       " 0.522881     0.519064     0.528557        0.474617      0.482932  \n",
       " 0.0668281    0.0412617    0.0340449       0.501711      0.500359  \n",
       " 0.0248613    0.025002     0.0311836       0.459779      0.458445  \n",
       " 0.0101914    0.00326563  -0.00354492  â€¦   0.339654      0.262234  \n",
       " 0.530727     0.509664     0.496281        0.554479      0.613654  \n",
       " 0.0324082    0.0312168    0.0303652       0.0200762     0.0140645 \n",
       " 0.463037     0.466908     0.472316        0.440996      0.454168  \n",
       " 0.0219473    0.0297539    0.0322109       0.512869      0.517795  \n",
       " 0.0201641    0.0232949    0.0299434   â€¦  -0.00972266   -0.006     \n",
       " 0.523789     0.519973     0.527756        0.0841953     0.0880527 \n",
       " 0.189791     0.136275     0.088043        0.0258809     0.0242656 \n",
       " â‹®                                     â‹±                           \n",
       " 0.66898      0.610455     0.619732        0.518408      0.511445  \n",
       " 0.450748     0.44474      0.436805    â€¦   0.457838      0.454674  \n",
       " 0.444354     0.437543     0.439016        0.0427578     0.057084  \n",
       " 0.456596     0.455771     0.456572        0.440363      0.445812  \n",
       " 0.519555     0.534432     0.519719        0.439734      0.445084  \n",
       " 0.446488     0.44782      0.452838        0.0169492     0.0307773 \n",
       " 0.471684     0.468688     0.468082    â€¦   0.529371      0.536582  \n",
       " 0.451314     0.422391     0.423492        0.524129      0.526965  \n",
       " 0.524936     0.528504     0.533434        0.462672      0.466127  \n",
       " 0.512912     0.51666      0.529971        0.444697      0.441621  \n",
       " 0.00380469  -0.0045918   -5.46875e-5      0.000652344  -0.00545117\n",
       " 0.439838     0.44093      0.446852    â€¦   0.459561      0.464877  \n",
       "\n",
       "[:, :, 3, 1] =\n",
       " 0.0325996     0.0328281   0.0329531   â€¦   0.0324668     0.0295312  \n",
       " 0.0320059     0.0342852   0.0354219       0.0241426     0.0279355  \n",
       " 0.525037      0.5204      0.525816        0.491463      0.500092   \n",
       " 0.101402      0.0858105   0.0635918       0.465867      0.468443   \n",
       " 0.0239961     0.0292461   0.049457        0.463125      0.450436   \n",
       " 0.0711875     0.0534375   0.0432188   â€¦   0.500994      0.466369   \n",
       " 0.634496      0.543076    0.506682        0.310826      0.434463   \n",
       " 0.0348027     0.0327129   0.0321074       0.000302734   0.000912109\n",
       " 0.477256      0.480385    0.490219        0.464764      0.460312   \n",
       " 0.0335566     0.0373027   0.0368105       0.477477      0.482359   \n",
       " 0.0469707     0.057207    0.0596523   â€¦   0.00942383    0.0209805  \n",
       " 0.51825       0.522943    0.532965        0.0366328     0.0491133  \n",
       " 0.0547637     0.0434004   0.0383555       0.0307734     0.028334   \n",
       " â‹®                                     â‹±                            \n",
       " 0.618135      0.552621    0.577713        0.506566      0.510783   \n",
       " 0.452238      0.442734    0.438576    â€¦   0.45807       0.465199   \n",
       " 0.439988      0.438617    0.437201        0.012998      0.0205156  \n",
       " 0.469072      0.467223    0.467369        0.449436      0.456711   \n",
       " 0.52759       0.532955    0.522902        0.439438      0.448256   \n",
       " 0.447072      0.443588    0.443539        0.00245313    0.00176953 \n",
       " 0.491191      0.485365    0.484471    â€¦   0.518977      0.524391   \n",
       " 0.460945      0.44808     0.457705        0.522885      0.523693   \n",
       " 0.527945      0.527219    0.521475        0.450594      0.457814   \n",
       " 0.51626       0.512307    0.512039        0.441635      0.443281   \n",
       " 0.000902344  -0.00530078  0.00102344     -0.00143945   -0.00449609 \n",
       " 0.44409       0.446691    0.452516    â€¦   0.457646      0.463234   \n",
       "\n",
       "...\n",
       "\n",
       "[:, :, 126, 1] =\n",
       " 0.616846   0.603412   0.593246   0.597828   â€¦   0.443053     0.446477  \n",
       " 0.522053   0.520902   0.52659    0.529713       0.588516     0.565168  \n",
       " 0.500059   0.51592    0.509541   0.501797       0.54149      0.540547  \n",
       " 0.61292    0.623885   0.636852   0.642193       0.556002     0.561602  \n",
       " 0.469693   0.477695   0.482346   0.493332       0.566121     0.569404  \n",
       " 0.614789   0.623117   0.624326   0.628553   â€¦   0.565072     0.566033  \n",
       " 0.469738   0.485609   0.501367   0.511127       0.469768     0.485705  \n",
       " 0.0465117  0.055125   0.0802852  0.129627       0.555334     0.550576  \n",
       " 0.61848    0.613139   0.631363   0.629906       0.559189     0.554609  \n",
       " 0.624113   0.6245     0.625785   0.62518        0.542687     0.551869  \n",
       " 0.460781   0.476205   0.479441   0.481746   â€¦   0.52323      0.524365  \n",
       " 0.501018   0.501609   0.499908   0.510629       0.552148     0.560895  \n",
       " 0.531699   0.544506   0.548314   0.550449       0.604604     0.595908  \n",
       " â‹®                                           â‹±                          \n",
       " 0.533559   0.535932   0.531316   0.519867       0.564949     0.554021  \n",
       " 0.470121   0.46468    0.465078   0.474461   â€¦   0.457797     0.448086  \n",
       " 0.549963   0.534828   0.512746   0.521344       0.526523     0.528998  \n",
       " 0.515301   0.487271   0.467338   0.469928       0.552877     0.548803  \n",
       " 0.477893   0.461428   0.490287   0.512146       0.54616      0.57276   \n",
       " 0.120559   0.0942266  0.0836191  0.0772852      0.45525      0.451992  \n",
       " 0.186992   0.209879   0.234563   0.276828   â€¦   0.578121     0.57974   \n",
       " 0.510615   0.49292    0.48458    0.488229       0.483084     0.477873  \n",
       " 0.453943   0.445469   0.446576   0.458184       0.602793     0.587557  \n",
       " 0.502332   0.496797   0.485141   0.471213       0.559316     0.566727  \n",
       " 0.0385684  0.0391426  0.0364824  0.0375898     -0.00234375  -0.00366211\n",
       " 0.0946953  0.0825488  0.0738945  0.0632988  â€¦   0.552385     0.541342  \n",
       "\n",
       "[:, :, 127, 1] =\n",
       " 0.608469   0.606137   0.609854   0.605627   â€¦   0.445191     0.449854  \n",
       " 0.517787   0.519029   0.527086   0.535662       0.590621     0.573416  \n",
       " 0.480135   0.485059   0.47992    0.474492       0.54192      0.536795  \n",
       " 0.615076   0.614658   0.617617   0.627697       0.567666     0.562031  \n",
       " 0.463309   0.4764     0.471535   0.476355       0.5725       0.575953  \n",
       " 0.62634    0.62584    0.625877   0.62817    â€¦   0.56109      0.560537  \n",
       " 0.46082    0.479908   0.504465   0.513471       0.456002     0.464775  \n",
       " 0.0467676  0.0473672  0.0672715  0.100832       0.553654     0.550359  \n",
       " 0.627258   0.632066   0.631609   0.621869       0.565857     0.559459  \n",
       " 0.626088   0.622881   0.623336   0.622107       0.558939     0.555037  \n",
       " 0.465834   0.472154   0.475723   0.477961   â€¦   0.515453     0.521674  \n",
       " 0.503064   0.504684   0.514668   0.51809        0.55282      0.553395  \n",
       " 0.541451   0.542875   0.546147   0.559211       0.608609     0.594662  \n",
       " â‹®                                           â‹±                          \n",
       " 0.524805   0.526246   0.526578   0.523832       0.551404     0.554094  \n",
       " 0.478264   0.478576   0.48235    0.498848   â€¦   0.453768     0.446016  \n",
       " 0.539617   0.53765    0.532363   0.529334       0.524557     0.52516   \n",
       " 0.515287   0.498006   0.476029   0.467625       0.553035     0.548957  \n",
       " 0.475479   0.471969   0.502533   0.531389       0.544158     0.556131  \n",
       " 0.121736   0.103576   0.0884297  0.0788418      0.446006     0.450713  \n",
       " 0.109525   0.121895   0.141736   0.171482   â€¦   0.579979     0.575365  \n",
       " 0.511785   0.487098   0.46285    0.471953       0.487816     0.492852  \n",
       " 0.454836   0.45516    0.456328   0.470668       0.598246     0.588691  \n",
       " 0.502227   0.500338   0.489248   0.483305       0.559324     0.568533  \n",
       " 0.0453164  0.0427656  0.0383281  0.0392773     -0.00366406  -0.00115039\n",
       " 0.0989453  0.0876426  0.0805469  0.0744414  â€¦   0.546553     0.53291   \n",
       "\n",
       "[:, :, 128, 1] =\n",
       " 0.604729   0.610234   0.625928   0.626262   â€¦   0.445465     0.443576  \n",
       " 0.523701   0.526932   0.526676   0.522873       0.600512     0.592449  \n",
       " 0.474438   0.462393   0.451348   0.450693       0.542838     0.538098  \n",
       " 0.620229   0.613652   0.619156   0.619156       0.561506     0.555246  \n",
       " 0.49893    0.486078   0.465904   0.48291        0.570602     0.59041   \n",
       " 0.611822   0.611223   0.607645   0.593002   â€¦   0.548813     0.554068  \n",
       " 0.468527   0.477461   0.490133   0.502861       0.447174     0.455871  \n",
       " 0.0585195  0.0557852  0.0621016  0.0666621      0.550805     0.551418  \n",
       " 0.630807   0.635543   0.630988   0.619234       0.55417      0.553574  \n",
       " 0.627031   0.620588   0.622582   0.622654       0.545645     0.553666  \n",
       " 0.470598   0.465096   0.471998   0.479594   â€¦   0.508191     0.516215  \n",
       " 0.513018   0.515012   0.525316   0.530031       0.561756     0.544582  \n",
       " 0.540488   0.543564   0.558195   0.579439       0.60498      0.59467   \n",
       " â‹®                                           â‹±                          \n",
       " 0.525994   0.525537   0.526111   0.521707       0.541902     0.543143  \n",
       " 0.503105   0.501791   0.502111   0.509734   â€¦   0.43499      0.447945  \n",
       " 0.561887   0.547826   0.541156   0.533107       0.519787     0.519539  \n",
       " 0.519285   0.504967   0.488758   0.480572       0.54616      0.54341   \n",
       " 0.455537   0.459197   0.494518   0.529367       0.538201     0.553123  \n",
       " 0.12957    0.115977   0.0863594  0.0782246      0.443248     0.448311  \n",
       " 0.0586973  0.0638242  0.0855781  0.116555   â€¦   0.591332     0.57865   \n",
       " 0.510918   0.493371   0.457135   0.461883       0.4871       0.502783  \n",
       " 0.472186   0.484883   0.482922   0.489934       0.59558      0.587629  \n",
       " 0.508592   0.50899    0.498947   0.47685        0.542457     0.55118   \n",
       " 0.0485254  0.0417891  0.0384629  0.0382578     -0.00348047  -0.00121484\n",
       " 0.087252   0.0893301  0.0915742  0.0905566  â€¦   0.550531     0.543537  \n",
       "\n",
       "[:, :, 1, 2] =\n",
       "  0.0305547    0.0307559    0.0312266   â€¦   0.0278242    0.0247109 \n",
       "  0.52902      0.529891     0.53301         0.045543     0.0426758 \n",
       "  0.527189     0.52951      0.527182        0.478506     0.487893  \n",
       "  0.0181426    0.0249043    0.0226074       0.509197     0.509277  \n",
       "  0.449357     0.452592     0.452174        0.5266       0.513934  \n",
       "  0.0495059    0.0597598    0.0768477   â€¦   0.522643     0.529566  \n",
       "  0.0358105    0.0347695    0.0291211       0.0342773    0.0343223 \n",
       "  0.0290234    0.0360039    0.0326914       0.535748     0.533127  \n",
       "  0.492773     0.499229     0.498012        0.0259258    0.033627  \n",
       "  0.0788555    0.0789746    0.0794785       0.075041     0.0807129 \n",
       "  0.377795     0.296367     0.205807    â€¦   0.0224961    0.0230527 \n",
       "  0.514891     0.519199     0.515969        0.457676     0.448385  \n",
       "  0.0511758    0.0453555    0.047166        0.0281836    0.0244766 \n",
       "  â‹®                                     â‹±                          \n",
       "  0.59934      0.745395     0.766344        0.538002     0.539492  \n",
       "  0.53298      0.532891     0.527764    â€¦   0.451902     0.465998  \n",
       "  0.0158906    0.0189746    0.0148555       0.445246     0.441814  \n",
       "  0.464336     0.463596     0.464738        0.449586     0.448607  \n",
       "  0.451699     0.450348     0.446137        0.518246     0.516711  \n",
       "  0.467895     0.465887     0.468168        0.448705     0.442674  \n",
       "  0.442084     0.445979     0.453096    â€¦   0.437736     0.439818  \n",
       "  0.53974      0.545902     0.553109        0.523607     0.52126   \n",
       "  0.521072     0.52999      0.528744        0.470379     0.467492  \n",
       "  0.523414     0.517311     0.513922        0.45951      0.455416  \n",
       " -0.00451953  -0.00505469  -0.00383594     -0.000804688  0.00170312\n",
       "  0.529129     0.524412     0.520223    â€¦   0.462604     0.463578  \n",
       "\n",
       "[:, :, 2, 2] =\n",
       "  0.0249727    0.0270566    0.0349238   â€¦   0.0249395   0.0213535  \n",
       "  0.528809     0.525719     0.527773        0.0423906   0.0415996  \n",
       "  0.538178     0.530889     0.531455        0.46224     0.473436   \n",
       "  0.0206543    0.0307285    0.0290898       0.515711    0.525744   \n",
       "  0.449402     0.446566     0.459135        0.491371    0.471035   \n",
       "  0.0989082    0.105785     0.102459    â€¦   0.527791    0.531      \n",
       "  0.0276953    0.0339277    0.0284844       0.0236309   0.028834   \n",
       "  0.0291543    0.0319258    0.0350039       0.517418    0.518859   \n",
       "  0.507379     0.507195     0.499713        0.032957    0.0335586  \n",
       "  0.105631     0.10959      0.115197        0.0275449   0.0335625  \n",
       "  0.533174     0.495828     0.439494    â€¦   0.0216172   0.0201719  \n",
       "  0.505285     0.514152     0.521459        0.452437    0.447902   \n",
       "  0.0265566    0.0295957    0.0371387       0.0262871   0.0273105  \n",
       "  â‹®                                     â‹±                          \n",
       "  0.532635     0.724332     0.814336        0.541469    0.541812   \n",
       "  0.533443     0.530574     0.533713    â€¦   0.452926    0.457471   \n",
       "  0.035668     0.050377     0.0551992       0.449518    0.450639   \n",
       "  0.472184     0.474152     0.465902        0.456445    0.459896   \n",
       "  0.459713     0.451977     0.445227        0.518316    0.51891    \n",
       "  0.46199      0.459301     0.462074        0.450523    0.447553   \n",
       "  0.445936     0.453949     0.452928    â€¦   0.447437    0.449459   \n",
       "  0.543646     0.546521     0.531521        0.523736    0.528119   \n",
       "  0.517977     0.526244     0.533852        0.535369    0.532672   \n",
       "  0.518232     0.519598     0.517787        0.447561    0.445998   \n",
       " -0.00366992  -0.00448047  -0.00393555     -0.00225781  0.000226562\n",
       "  0.519619     0.515689     0.514484    â€¦   0.462768    0.458359   \n",
       "\n",
       "[:, :, 3, 2] =\n",
       "  0.0300703    0.0261133   0.0331758   â€¦   0.0240625    0.0229121 \n",
       "  0.528574     0.528615    0.527266        0.0420371    0.0456445 \n",
       "  0.538041     0.534748    0.535066        0.450123     0.453475  \n",
       "  0.031584     0.0307187   0.020166        0.52573      0.533719  \n",
       "  0.452184     0.458154    0.47035         0.458424     0.442674  \n",
       "  0.0585918    0.0398242   0.0304121   â€¦   0.533732     0.531861  \n",
       "  0.0251387    0.0312207   0.0319922       0.0194512    0.0235957 \n",
       "  0.034166     0.0337832   0.0350137       0.518129     0.516311  \n",
       "  0.48882      0.486437    0.482416        0.0358516    0.0382813 \n",
       "  0.277289     0.297172    0.31768         0.0168457    0.0167051 \n",
       "  0.544674     0.541609    0.538979    â€¦   0.0247812    0.0251563 \n",
       "  0.499766     0.509043    0.518773        0.447016     0.453145  \n",
       "  0.0275215    0.0355488   0.042541        0.024748     0.0282871 \n",
       "  â‹®                                    â‹±                          \n",
       "  0.456033     0.644336    0.801578        0.530443     0.532686  \n",
       "  0.535213     0.539047    0.538225    â€¦   0.446223     0.448203  \n",
       "  0.0596152    0.0624902   0.0582734       0.450303     0.454033  \n",
       "  0.463654     0.464822    0.462488        0.454766     0.469928  \n",
       "  0.455947     0.458205    0.459791        0.512734     0.51323   \n",
       "  0.458178     0.455432    0.456678        0.448922     0.445691  \n",
       "  0.440365     0.441818    0.444242    â€¦   0.449615     0.453648  \n",
       "  0.518816     0.522832    0.51225         0.518273     0.51941   \n",
       "  0.51342      0.518582    0.537057        0.527412     0.531617  \n",
       "  0.516227     0.523639    0.520213        0.446053     0.447961  \n",
       " -0.00279883  -0.0039082  -0.00402344     -0.00338281  -0.00122656\n",
       "  0.499051     0.506844    0.506936    â€¦   0.455867     0.45957   \n",
       "\n",
       "...\n",
       "\n",
       "[:, :, 126, 2] =\n",
       "  0.527537    0.513094    0.528689   â€¦  0.514975   0.525098   0.531768 \n",
       "  0.103955    0.0626953   0.0402871     0.519652   0.499322   0.472707 \n",
       "  0.56902     0.585709    0.58701       0.0279668  0.0351387  0.0485176\n",
       "  0.547203    0.547258    0.548949      0.51217    0.518846   0.54776  \n",
       "  0.529475    0.519603    0.503797      0.537414   0.547131   0.545621 \n",
       "  0.552184    0.549729    0.546721   â€¦  0.528676   0.544443   0.552879 \n",
       "  0.596264    0.598496    0.587777      0.505605   0.474574   0.459635 \n",
       "  0.161146    0.118314    0.0921348     0.631381   0.594281   0.542184 \n",
       "  0.541936    0.548795    0.54415       0.472795   0.4759     0.492635 \n",
       "  0.0574512   0.0573516   0.0584805     0.545283   0.538469   0.536709 \n",
       "  0.541117    0.537012    0.543975   â€¦  0.482145   0.49698    0.528449 \n",
       "  0.526967    0.533043    0.539039      0.520877   0.508031   0.489648 \n",
       "  0.0568984   0.127932    0.232666      0.555465   0.584377   0.586453 \n",
       "  â‹®                                  â‹±  â‹®                              \n",
       "  0.586889    0.583514    0.586482      0.560728   0.566072   0.566373 \n",
       "  0.486154    0.475652    0.46499    â€¦  0.548709   0.550898   0.556707 \n",
       "  0.596314    0.600658    0.590021      0.507271   0.492248   0.473576 \n",
       "  0.0483086   0.0450391   0.0440449     0.583994   0.6036     0.614902 \n",
       "  0.500154    0.50468     0.503982      0.536336   0.527975   0.519152 \n",
       "  0.0678574   0.0734102   0.0723965     0.559402   0.563439   0.571348 \n",
       "  0.530922    0.537086    0.549078   â€¦  0.529334   0.522195   0.524061 \n",
       "  0.552584    0.546359    0.558092      0.440178   0.445229   0.449617 \n",
       "  0.538223    0.549053    0.555227      0.510598   0.518898   0.531264 \n",
       "  0.151406    0.163377    0.202027      0.601008   0.607586   0.589039 \n",
       " -0.0109922  -0.0101562  -0.0110391     0.0357949  0.0393711  0.0393906\n",
       "  0.0651992   0.0952344   0.116668   â€¦  0.469252   0.47408    0.496033 \n",
       "\n",
       "[:, :, 127, 2] =\n",
       " 0.499262   0.48682    0.506648   â€¦  0.5149     0.526242   0.532553 \n",
       " 0.11715    0.0911914  0.0547148     0.526914   0.527928   0.502984 \n",
       " 0.564957   0.578418   0.586486      0.0273477  0.0228633  0.0291953\n",
       " 0.550734   0.557908   0.569818      0.523664   0.534047   0.563541 \n",
       " 0.5391     0.526574   0.506186      0.546594   0.561311   0.554406 \n",
       " 0.547607   0.542551   0.544809   â€¦  0.523465   0.532385   0.534828 \n",
       " 0.597002   0.592141   0.587066      0.498104   0.474002   0.449465 \n",
       " 0.147344   0.12948    0.107953      0.636471   0.590688   0.532102 \n",
       " 0.547785   0.546795   0.541713      0.494479   0.490674   0.496396 \n",
       " 0.0605313  0.0617891  0.0646777     0.548361   0.529039   0.527062 \n",
       " 0.532852   0.535545   0.541898   â€¦  0.502941   0.52891    0.55318  \n",
       " 0.523322   0.532566   0.532488      0.504709   0.488699   0.46757  \n",
       " 0.0454961  0.0939941  0.17943       0.548047   0.580383   0.588818 \n",
       " â‹®                                â‹±  â‹®                              \n",
       " 0.587537   0.589316   0.589961      0.559246   0.564068   0.556809 \n",
       " 0.482043   0.471428   0.463301   â€¦  0.539473   0.54124    0.548652 \n",
       " 0.584248   0.577508   0.5879        0.500279   0.492268   0.472639 \n",
       " 0.053584   0.0507031  0.0473301     0.571264   0.577107   0.590691 \n",
       " 0.501842   0.508131   0.522221      0.482654   0.476939   0.467068 \n",
       " 0.0685215  0.0698887  0.0637227     0.567127   0.563393   0.557982 \n",
       " 0.543436   0.551004   0.548824   â€¦  0.538893   0.515428   0.523291 \n",
       " 0.565275   0.547598   0.549283      0.461604   0.461812   0.462002 \n",
       " 0.554518   0.545853   0.536186      0.523445   0.52426    0.534002 \n",
       " 0.258295   0.310439   0.363187      0.562236   0.573145   0.564424 \n",
       " 0.0319297  0.0639844  0.0958613     0.0405254  0.0416191  0.0420137\n",
       " 0.0650859  0.0617852  0.0600801  â€¦  0.485082   0.489521   0.496338 \n",
       "\n",
       "[:, :, 128, 2] =\n",
       " 0.504086   0.492004   0.497598   â€¦  0.527947   0.530979   0.531629 \n",
       " 0.12725    0.118219   0.0725254     0.521295   0.534301   0.52957  \n",
       " 0.569129   0.579568   0.584605      0.0334687  0.0323047  0.0245879\n",
       " 0.5581     0.559627   0.558523      0.529535   0.559313   0.590629 \n",
       " 0.532719   0.523846   0.507295      0.543406   0.546172   0.547311 \n",
       " 0.551076   0.537602   0.548215   â€¦  0.521895   0.541797   0.554018 \n",
       " 0.605187   0.605064   0.610342      0.478203   0.460945   0.450828 \n",
       " 0.102475   0.119775   0.121939      0.625613   0.581605   0.531557 \n",
       " 0.559211   0.540418   0.533684      0.513947   0.494621   0.493504 \n",
       " 0.0633008  0.0637227  0.063293      0.530734   0.494176   0.498234 \n",
       " 0.535213   0.543936   0.54916    â€¦  0.532244   0.551189   0.562887 \n",
       " 0.538604   0.543963   0.546193      0.489938   0.478574   0.464221 \n",
       " 0.0379805  0.078125   0.144973      0.5465     0.576502   0.597164 \n",
       " â‹®                                â‹±  â‹®                              \n",
       " 0.590627   0.601563   0.596668      0.533262   0.526039   0.515873 \n",
       " 0.485955   0.471779   0.465582   â€¦  0.536676   0.534143   0.539033 \n",
       " 0.574859   0.577623   0.603695      0.495826   0.482355   0.468016 \n",
       " 0.0661426  0.0651719  0.063543      0.564287   0.57457    0.582363 \n",
       " 0.481764   0.488014   0.506684      0.45926    0.444982   0.444197 \n",
       " 0.0716758  0.0731172  0.0716992     0.577033   0.570883   0.562986 \n",
       " 0.552023   0.555396   0.550443   â€¦  0.552988   0.53657    0.535674 \n",
       " 0.559406   0.547562   0.544928      0.494961   0.485191   0.474822 \n",
       " 0.568766   0.557148   0.546064      0.536154   0.530969   0.51568  \n",
       " 0.391367   0.439766   0.472598      0.526004   0.537803   0.522816 \n",
       " 0.180953   0.258824   0.333236      0.0465293  0.0461172  0.0430391\n",
       " 0.0706133  0.0642012  0.0563145  â€¦  0.448217   0.463502   0.473234 \n",
       "\n",
       "[:, :, 1, 3] =\n",
       " 0.031252     0.0304512    0.0255312   â€¦   0.0621855    0.0717285 \n",
       " 0.106656     0.114461     0.11865         0.0181602    0.0207344 \n",
       " 0.687711     0.629084     0.549522        0.525559     0.520451  \n",
       " 0.104861     0.113438     0.0963242       0.53485      0.536279  \n",
       " 0.450785     0.446766     0.450072        0.559385     0.550979  \n",
       " 0.0217656    0.0235137    0.0267617   â€¦   0.0242539    0.0254883 \n",
       " 0.530189     0.544805     0.546975        0.0309785    0.0335801 \n",
       " 0.139223     0.144566     0.138318        0.0262363    0.025207  \n",
       " 0.472201     0.475137     0.480945        0.423998     0.468439  \n",
       " 0.0202695    0.0272891    0.0371934       0.450031     0.446691  \n",
       " 0.533527     0.5346       0.534119    â€¦   0.440373     0.434607  \n",
       " 0.532234     0.523896     0.518014        0.0312324    0.042252  \n",
       " 0.0207461    0.028207     0.030293        0.523348     0.519881  \n",
       " â‹®                                     â‹±                          \n",
       " 0.72099      0.639422     0.551951        0.515197     0.504998  \n",
       " 0.451271     0.439652     0.434703    â€¦   0.529129     0.524434  \n",
       " 0.500316     0.509844     0.509633        0.0650273    0.0735957 \n",
       " 0.446111     0.456414     0.446219        0.442727     0.441383  \n",
       " 0.527902     0.52833      0.534512        0.445246     0.444215  \n",
       " 0.0688008    0.0740762    0.0735762       0.0335566    0.0301953 \n",
       " 0.44868      0.450803     0.452146    â€¦   0.43675      0.43523   \n",
       " 0.151725     0.151426     0.142014        0.474613     0.47227   \n",
       " 0.740117     0.605693     0.530131        0.447982     0.450225  \n",
       " 0.540416     0.53427      0.531199        0.45559      0.45334   \n",
       " 0.00112695  -0.00195508  -0.00262891     -0.00304883  -0.00596094\n",
       " 0.438904     0.438416     0.443109    â€¦   0.460984     0.465748  \n",
       "\n",
       "[:, :, 2, 3] =\n",
       " 0.0282598     0.0273301    0.0237715   â€¦   0.0364395    0.0494453 \n",
       " 0.139908      0.162553     0.182256        0.0218223    0.0200957 \n",
       " 0.741348      0.720104     0.645408        0.519193     0.518848  \n",
       " 0.0890781     0.066082     0.0519824       0.5331       0.523957  \n",
       " 0.466773      0.464586     0.465789        0.550625     0.542289  \n",
       " 0.0257051     0.0292559    0.0282207   â€¦   0.0281641    0.0261934 \n",
       " 0.532217      0.529143     0.542432        0.0367969    0.0326426 \n",
       " 0.152445      0.145676     0.141117        0.0289121    0.0281934 \n",
       " 0.492424      0.493152     0.496777        0.518352     0.528037  \n",
       " 0.0640352     0.0693887    0.0826328       0.449062     0.436494  \n",
       " 0.53176       0.532789     0.535576    â€¦   0.45024      0.44093   \n",
       " 0.532154      0.53368      0.521879        0.0196191    0.0235098 \n",
       " 0.027498      0.0311152    0.0254883       0.519643     0.514311  \n",
       " â‹®                                      â‹±                          \n",
       " 0.699289      0.659502     0.584107        0.521963     0.511285  \n",
       " 0.436965      0.434309     0.439818    â€¦   0.526814     0.52826   \n",
       " 0.472707      0.479072     0.482193        0.0637969    0.0545313 \n",
       " 0.454492      0.461348     0.455219        0.45626      0.45283   \n",
       " 0.526623      0.527691     0.532316        0.444295     0.44173   \n",
       " 0.059416      0.0615742    0.0649746       0.0302324    0.0266758 \n",
       " 0.449994      0.451775     0.454779    â€¦   0.445248     0.437047  \n",
       " 0.205457      0.176256     0.150127        0.506078     0.509535  \n",
       " 0.736842      0.598217     0.519723        0.443854     0.445494  \n",
       " 0.527475      0.524008     0.518777        0.453855     0.450652  \n",
       " 0.000734375  -0.00188672  -0.00178906     -0.00323633  -0.00692773\n",
       " 0.446814      0.447303     0.448465    â€¦   0.455756     0.462914  \n",
       "\n",
       "[:, :, 3, 3] =\n",
       " 0.0206543     0.0230996    0.0274785   â€¦   0.0324824    0.0377637 \n",
       " 0.258445      0.289986     0.317156        0.029377     0.0181699 \n",
       " 0.737469      0.765738     0.748025        0.510766     0.511668  \n",
       " 0.0913789     0.0787676    0.0716016       0.530141     0.522289  \n",
       " 0.462656      0.463166     0.463416        0.541436     0.559771  \n",
       " 0.0323027     0.034875     0.0288379   â€¦   0.0250117    0.0226777 \n",
       " 0.53633       0.532877     0.535428        0.0358398    0.0315371 \n",
       " 0.159779      0.158816     0.160725        0.0280293    0.0277637 \n",
       " 0.517262      0.512867     0.511205        0.507701     0.506283  \n",
       " 0.0957852     0.107453     0.136529        0.463473     0.471463  \n",
       " 0.524314      0.528645     0.531687    â€¦   0.455223     0.449744  \n",
       " 0.533188      0.529523     0.518234        0.0484961    0.0383379 \n",
       " 0.0296035     0.0308359    0.0221035       0.521574     0.524533  \n",
       " â‹®                                      â‹±                          \n",
       " 0.684869      0.715666     0.64135         0.526252     0.508512  \n",
       " 0.445836      0.447209     0.447203    â€¦   0.525773     0.52976   \n",
       " 0.446213      0.446613     0.449711        0.0777012    0.0758359 \n",
       " 0.459191      0.462729     0.458936        0.451352     0.455461  \n",
       " 0.527525      0.52649      0.524389        0.442336     0.451187  \n",
       " 0.0895176     0.0782637    0.0658008       0.026375     0.0259258 \n",
       " 0.459646      0.458172     0.460252    â€¦   0.438326     0.432816  \n",
       " 0.323373      0.285082     0.245277        0.555549     0.574625  \n",
       " 0.686363      0.553588     0.509129        0.443988     0.443775  \n",
       " 0.519695      0.510244     0.504172        0.452166     0.450162  \n",
       " 0.000431641  -0.00152734  -0.00126563     -0.00342969  -0.00786523\n",
       " 0.445406      0.445938     0.448184    â€¦   0.450498     0.456789  \n",
       "\n",
       "...\n",
       "\n",
       "[:, :, 126, 3] =\n",
       " 0.461336   0.459924   0.461881   0.463484   â€¦  0.524197  0.534441  0.530064\n",
       " 0.505191   0.497783   0.511385   0.513041      0.612416  0.611188  0.600625\n",
       " 0.47893    0.485098   0.48508    0.475732      0.58507   0.580318  0.57309 \n",
       " 0.498768   0.507129   0.503273   0.533561      0.560043  0.557861  0.557566\n",
       " 0.47874    0.496977   0.519141   0.53208       0.50907   0.526648  0.516795\n",
       " 0.641271   0.638074   0.631531   0.638168   â€¦  0.55677   0.586182  0.598498\n",
       " 0.515547   0.502029   0.486926   0.484873      0.495227  0.469451  0.454033\n",
       " 0.0543477  0.0549863  0.0519668  0.0544141     0.521082  0.524555  0.533848\n",
       " 0.612746   0.611941   0.619625   0.628619      0.564645  0.563266  0.565184\n",
       " 0.0560117  0.0563945  0.0567969  0.0575957     0.537814  0.528365  0.526945\n",
       " 0.535836   0.551797   0.561478   0.563857   â€¦  0.52608   0.519553  0.517604\n",
       " 0.498971   0.506689   0.527135   0.553855      0.576729  0.577896  0.567117\n",
       " 0.528457   0.534348   0.538727   0.557529      0.537811  0.540895  0.537475\n",
       " â‹®                                           â‹±  â‹®                           \n",
       " 0.451771   0.451848   0.454041   0.459746      0.551881  0.549248  0.553883\n",
       " 0.456873   0.453508   0.461227   0.463271   â€¦  0.539365  0.552953  0.541008\n",
       " 0.480988   0.487447   0.513801   0.542463      0.51332   0.506203  0.516367\n",
       " 0.593449   0.606529   0.614928   0.617664      0.539137  0.545371  0.547852\n",
       " 0.500061   0.480049   0.461771   0.460047      0.541432  0.531424  0.524625\n",
       " 0.0701719  0.0614492  0.0601133  0.0568965     0.503512  0.519889  0.52748 \n",
       " 0.610555   0.611672   0.611709   0.607992   â€¦  0.454643  0.462666  0.462389\n",
       " 0.531359   0.539742   0.540348   0.54958       0.46991   0.470535  0.45617 \n",
       " 0.596828   0.614615   0.62759    0.610992      0.553281  0.547668  0.552832\n",
       " 0.532602   0.538746   0.538967   0.534057      0.545119  0.541252  0.5354  \n",
       " 0.12291    0.115012   0.108154   0.0999004     0.113084  0.116906  0.115254\n",
       " 0.298678   0.271439   0.189049   0.150496   â€¦  0.52983   0.534691  0.541246\n",
       "\n",
       "[:, :, 127, 3] =\n",
       " 0.457461   0.452818   0.45692    â€¦  0.523535   0.52567    0.520225 \n",
       " 0.536535   0.503297   0.503455      0.605252   0.611332   0.604049 \n",
       " 0.47893    0.477211   0.485816      0.605074   0.60308    0.598191 \n",
       " 0.498016   0.497445   0.490406      0.55699    0.559131   0.555272 \n",
       " 0.514359   0.524566   0.530289      0.503965   0.501385   0.49373  \n",
       " 0.622699   0.626408   0.635475   â€¦  0.558137   0.582744   0.599369 \n",
       " 0.515281   0.493879   0.472795      0.504809   0.482037   0.458937 \n",
       " 0.0505801  0.0483457  0.0510781     0.535803   0.539398   0.539918 \n",
       " 0.617439   0.613383   0.622096      0.550721   0.547885   0.557568 \n",
       " 0.0542461  0.0555332  0.0569785     0.543686   0.545428   0.551646 \n",
       " 0.525057   0.548492   0.56257    â€¦  0.516268   0.516764   0.525404 \n",
       " 0.504008   0.519459   0.531609      0.59048    0.595332   0.578301 \n",
       " 0.526152   0.527332   0.539064      0.531244   0.551117   0.55082  \n",
       " â‹®                                â‹±  â‹®                              \n",
       " 0.44573    0.44507    0.45002       0.550648   0.547791   0.554397 \n",
       " 0.456529   0.448096   0.447498   â€¦  0.543443   0.542758   0.534443 \n",
       " 0.490035   0.473803   0.488629      0.51058    0.50002    0.516492 \n",
       " 0.615695   0.620258   0.611195      0.547453   0.550641   0.553119 \n",
       " 0.484646   0.464826   0.44352       0.569889   0.557287   0.556699 \n",
       " 0.0718105  0.0661191  0.0624805     0.49848    0.514498   0.534045 \n",
       " 0.612133   0.605719   0.602555   â€¦  0.450906   0.45123    0.45107  \n",
       " 0.499377   0.524904   0.536998      0.478617   0.478594   0.467748 \n",
       " 0.586523   0.588549   0.598125      0.555205   0.555645   0.56232  \n",
       " 0.531861   0.531113   0.529184      0.538947   0.548166   0.556881 \n",
       " 0.0550156  0.0575098  0.0562812     0.0610293  0.0608496  0.0632988\n",
       " 0.268324   0.245686   0.1834     â€¦  0.535414   0.530937   0.537687 \n",
       "\n",
       "[:, :, 128, 3] =\n",
       " 0.465225   0.457762   0.460227   â€¦  0.511365   0.508158   0.509711 \n",
       " 0.563656   0.519865   0.498766      0.596094   0.606324   0.603709 \n",
       " 0.470637   0.468736   0.486104      0.619539   0.615898   0.619113 \n",
       " 0.483178   0.496268   0.50159       0.551398   0.560861   0.565379 \n",
       " 0.535244   0.536439   0.540742      0.494648   0.4984     0.493576 \n",
       " 0.629484   0.629537   0.633213   â€¦  0.539023   0.565809   0.583053 \n",
       " 0.496133   0.477959   0.468504      0.517758   0.49491    0.466791 \n",
       " 0.0429473  0.0402383  0.0503594     0.555959   0.554107   0.553205 \n",
       " 0.617564   0.621115   0.629488      0.542025   0.540059   0.54443  \n",
       " 0.0541465  0.0567383  0.0583574     0.543914   0.54218    0.547469 \n",
       " 0.509387   0.526479   0.548471   â€¦  0.527941   0.521338   0.518256 \n",
       " 0.514779   0.523799   0.526047      0.600496   0.603191   0.590367 \n",
       " 0.534131   0.527176   0.536742      0.544213   0.552768   0.554629 \n",
       " â‹®                                â‹±  â‹®                              \n",
       " 0.449203   0.455021   0.458033      0.553975   0.550805   0.554006 \n",
       " 0.455355   0.447484   0.445059   â€¦  0.532053   0.519533   0.51323  \n",
       " 0.562205   0.527059   0.511418      0.523967   0.527676   0.529139 \n",
       " 0.616006   0.615883   0.60758       0.551176   0.553068   0.549652 \n",
       " 0.471637   0.463562   0.454473      0.591977   0.57684    0.575643 \n",
       " 0.0709297  0.0644082  0.0657051     0.513963   0.522113   0.528895 \n",
       " 0.60424    0.603262   0.602469   â€¦  0.458711   0.441053   0.434811 \n",
       " 0.477707   0.503406   0.515939      0.483098   0.483934   0.458326 \n",
       " 0.566619   0.570729   0.592365      0.564127   0.566307   0.567643 \n",
       " 0.531891   0.523902   0.518541      0.554207   0.561484   0.550828 \n",
       " 0.0439766  0.0458496  0.0448086     0.0506816  0.0461738  0.0479355\n",
       " 0.231434   0.205803   0.168869   â€¦  0.536687   0.537203   0.54365  \n",
       "\n",
       "[:, :, 1, 4] =\n",
       "  0.0276152    0.0256582   â€¦   0.0866465    0.0848105  0.0783105 \n",
       "  0.524715     0.522477        0.0466113    0.0455     0.0422734 \n",
       "  0.507799     0.495941        0.525988     0.520451   0.51925   \n",
       "  0.0508164    0.0691563       0.526725     0.527814   0.522895  \n",
       "  0.454891     0.462955        0.451562     0.459311   0.466355  \n",
       "  0.0296953    0.0245371   â€¦   0.486355     0.484467   0.493363  \n",
       "  0.0229062    0.0219512       0.0237207    0.0249648  0.0223848 \n",
       "  0.037209     0.0371523       0.533223     0.531416   0.53558   \n",
       "  0.497447     0.503465        0.0183809    0.015752   0.0152207 \n",
       "  0.0798965    0.0710488       0.454961     0.458318   0.465621  \n",
       "  0.530346     0.526221    â€¦   0.499914     0.484912   0.469     \n",
       "  0.507611     0.504307        0.443523     0.434129   0.435344  \n",
       "  0.0315312    0.0283359       0.44873      0.449176   0.449139  \n",
       "  â‹®                        â‹±   â‹®                                 \n",
       "  0.0707129    0.0671973       0.446449     0.448652   0.44518   \n",
       "  0.536418     0.509648    â€¦   0.442699     0.435891   0.438104  \n",
       "  0.0266016    0.0368633       0.459887     0.452359   0.459496  \n",
       "  0.484012     0.473766        0.0105098    0.0154453  0.0164824 \n",
       "  0.521691     0.523309        0.453662     0.452533   0.442986  \n",
       "  0.0308145    0.0331914       0.0283398    0.031543   0.0326758 \n",
       "  0.451584     0.454865    â€¦   0.451953     0.461043   0.474078  \n",
       "  0.701875     0.701928        0.469131     0.471807   0.476723  \n",
       "  0.491279     0.508721        0.0147363    0.0153145  0.0147168 \n",
       "  0.906313     0.768197        0.446242     0.45198    0.454688  \n",
       " -4.10156e-5  -0.00420898     -0.000134766  0.011291   0.00646875\n",
       "  0.459871     0.457979    â€¦   0.515885     0.514467   0.511445  \n",
       "\n",
       "[:, :, 2, 4] =\n",
       " 0.0196387    0.0238652    0.0216992   â€¦   0.0649727   0.0773359   0.0819746 \n",
       " 0.518875     0.523203     0.526086        0.0420234   0.045248    0.0420977 \n",
       " 0.515865     0.509541     0.509848        0.528154    0.525445    0.525826  \n",
       " 0.078377     0.0947656    0.0766035       0.526576    0.530822    0.531055  \n",
       " 0.485537     0.482834     0.493307        0.44382     0.4499      0.450617  \n",
       " 0.0277637    0.0189609    0.0258301   â€¦   0.540117    0.53708     0.54517   \n",
       " 0.0252656    0.0246484    0.0205273       0.0235645   0.0276309   0.0269238 \n",
       " 0.0376309    0.0375215    0.037666        0.535945    0.529031    0.533932  \n",
       " 0.507047     0.512629     0.519107        0.0149688   0.0136895   0.0187305 \n",
       " 0.0571758    0.0707129    0.0922344       0.469496    0.46966     0.476049  \n",
       " 0.52959      0.527059     0.529262    â€¦   0.521594    0.516867    0.507522  \n",
       " 0.512572     0.519078     0.526203        0.439178    0.437605    0.438111  \n",
       " 0.0508926    0.0617559    0.0742891       0.443377    0.447984    0.448012  \n",
       " â‹®                                     â‹±   â‹®                                 \n",
       " 0.0759356    0.072123     0.0692227       0.443861    0.444049    0.445902  \n",
       " 0.550932     0.516273     0.505551    â€¦   0.462322    0.445604    0.439234  \n",
       " 0.0624785    0.0728887    0.0695957       0.452668    0.451701    0.455826  \n",
       " 0.512273     0.503842     0.495166        0.00717187  0.00708594  0.00994141\n",
       " 0.528049     0.523906     0.527994        0.452961    0.443049    0.432066  \n",
       " 0.0375449    0.0353281    0.0300762       0.0266777   0.0313613   0.0310391 \n",
       " 0.443939     0.448867     0.452742    â€¦   0.443799    0.447338    0.451238  \n",
       " 0.736248     0.720658     0.69276         0.484584    0.481895    0.485029  \n",
       " 0.430457     0.507988     0.514324        0.0134629   0.0084668   0.00738672\n",
       " 0.958242     0.86501      0.718406        0.455455    0.456596    0.456184  \n",
       " 0.00144727  -0.00385156  -0.00317578     -0.00257227  0.00877734  0.00834375\n",
       " 0.459326     0.458111     0.455994    â€¦   0.519496    0.523734    0.520744  \n",
       "\n",
       "[:, :, 3, 4] =\n",
       " 0.0111465    0.0193203   0.0203555   â€¦   0.0202344   0.0297734   0.0367617 \n",
       " 0.507094     0.515727    0.522428        0.0441914   0.049748    0.0509336 \n",
       " 0.513164     0.511139    0.523463        0.524471    0.521365    0.522633  \n",
       " 0.0569102    0.0313613   0.0135098       0.527516    0.532693    0.533605  \n",
       " 0.507945     0.508512    0.512039        0.442467    0.459219    0.453168  \n",
       " 0.0301289    0.0248535   0.0233691   â€¦   0.502848    0.499719    0.511266  \n",
       " 0.0297441    0.0284941   0.0238125       0.0222695   0.0282129   0.0299707 \n",
       " 0.0279199    0.025416    0.0295957       0.518785    0.513209    0.527416  \n",
       " 0.531773     0.522992    0.522537        0.0564141   0.0398906   0.0306875 \n",
       " 0.149477     0.204484    0.263818        0.491754    0.497611    0.50124   \n",
       " 0.525852     0.526904    0.531457    â€¦   0.524475    0.52866     0.527801  \n",
       " 0.520658     0.517693    0.515787        0.436832    0.43725     0.44308   \n",
       " 0.0822637    0.0860957   0.0966523       0.442869    0.447986    0.448006  \n",
       " â‹®                                    â‹±   â‹®                                 \n",
       " 0.0752598    0.0740176   0.0698711       0.451354    0.447908    0.445936  \n",
       " 0.585258     0.539305    0.517086    â€¦   0.455613    0.443842    0.436773  \n",
       " 0.0432617    0.0419004   0.035625        0.443414    0.442871    0.44598   \n",
       " 0.528059     0.527105    0.525295        0.0127871   0.00941211  0.00739453\n",
       " 0.526035     0.520695    0.524416        0.455738    0.441732    0.431846  \n",
       " 0.0347539    0.0330488   0.0284336       0.0439316   0.0450996   0.0415664 \n",
       " 0.449785     0.45173     0.453438    â€¦   0.446754    0.447766    0.440189  \n",
       " 0.727348     0.722668    0.671092        0.492627    0.489803    0.50243   \n",
       " 0.325504     0.442201    0.501984        0.0156426   0.00979687  0.0056875 \n",
       " 0.905215     0.880578    0.753951        0.462902    0.462152    0.460883  \n",
       " 0.00294141  -0.0030293  -0.00399414     -0.00508594  0.00633984  0.0102773 \n",
       " 0.458014     0.45608     0.45708     â€¦   0.531879    0.536863    0.529166  \n",
       "\n",
       "...\n",
       "\n",
       "[:, :, 126, 4] =\n",
       "  0.613947     0.610547     0.608484    â€¦  0.523264   0.522955   0.517557\n",
       "  0.526482     0.521953     0.519732       0.544978   0.52466    0.520006\n",
       "  0.569908     0.572228     0.565281       0.465051   0.466242   0.464256\n",
       "  0.466672     0.469303     0.459854       0.527264   0.53182    0.532514\n",
       "  0.574441     0.566295     0.566584       0.491215   0.498316   0.510516\n",
       "  0.563166     0.554357     0.546795    â€¦  0.498268   0.494652   0.491473\n",
       "  0.566777     0.559424     0.557967       0.66574    0.674541   0.698533\n",
       "  0.0888125    0.0814512    0.0729785      0.574602   0.558635   0.546574\n",
       "  0.527984     0.521748     0.525074       0.525578   0.531012   0.532236\n",
       "  0.171531     0.20784      0.217506       0.527836   0.528527   0.530135\n",
       "  0.539182     0.539398     0.54391     â€¦  0.452471   0.449246   0.448729\n",
       "  0.530535     0.539754     0.546898       0.609871   0.606832   0.607383\n",
       "  0.196688     0.322723     0.441463       0.533666   0.527816   0.511553\n",
       "  â‹®                                     â‹±  â‹®                             \n",
       "  0.582387     0.577197     0.57752        0.46107    0.453918   0.455617\n",
       "  0.593623     0.593955     0.587316    â€¦  0.538391   0.533211   0.52827 \n",
       "  0.640363     0.688438     0.709557       0.43243    0.444916   0.443033\n",
       "  0.0757441    0.0851816    0.0966699      0.573428   0.570895   0.571947\n",
       "  0.544492     0.545014     0.53701        0.528803   0.529619   0.519219\n",
       "  0.549098     0.555863     0.569828       0.48707    0.479758   0.473514\n",
       "  0.0510039    0.0464004    0.0539629   â€¦  0.573215   0.582547   0.580574\n",
       "  0.55632      0.551898     0.553514       0.45751    0.45624    0.456178\n",
       "  0.493756     0.450219     0.437025       0.520887   0.516568   0.518809\n",
       "  0.126182     0.0957734    0.0848848      0.566914   0.573764   0.595316\n",
       " -0.00601172  -0.00496875  -0.00634375     0.0353242  0.0335098  0.03525 \n",
       "  0.0878262    0.0760996    0.0663437   â€¦  0.479322   0.483617   0.489652\n",
       "\n",
       "[:, :, 127, 4] =\n",
       "  0.616627     0.619535     0.614148    â€¦  0.518408   0.515348   0.515043 \n",
       "  0.540066     0.540717     0.528213       0.544139   0.537963   0.526391 \n",
       "  0.546672     0.565637     0.568387       0.467652   0.469834   0.462027 \n",
       "  0.488777     0.494967     0.490891       0.517271   0.518107   0.526656 \n",
       "  0.570473     0.564916     0.570246       0.482068   0.495164   0.507072 \n",
       "  0.549445     0.545211     0.54916     â€¦  0.488438   0.477947   0.492035 \n",
       "  0.559359     0.562891     0.563648       0.673555   0.676025   0.663312 \n",
       "  0.0911953    0.0882578    0.0963242      0.540699   0.522779   0.515938 \n",
       "  0.54042      0.535262     0.52901        0.507811   0.50857    0.511148 \n",
       "  0.112678     0.171709     0.232574       0.531566   0.53166    0.532229 \n",
       "  0.54127      0.538988     0.539543    â€¦  0.44923    0.44823    0.442393 \n",
       "  0.535793     0.541893     0.546648       0.600955   0.604734   0.618365 \n",
       "  0.112109     0.220678     0.359285       0.533008   0.525902   0.512123 \n",
       "  â‹®                                     â‹±  â‹®                              \n",
       "  0.583578     0.575902     0.57166        0.449121   0.451918   0.454986 \n",
       "  0.601777     0.619068     0.605762    â€¦  0.554932   0.535891   0.525225 \n",
       "  0.670766     0.706654     0.698465       0.433031   0.441996   0.444672 \n",
       "  0.086709     0.070582     0.0686426      0.583521   0.574781   0.574539 \n",
       "  0.529709     0.522818     0.526814       0.524113   0.521244   0.519611 \n",
       "  0.542939     0.55633      0.580414       0.459211   0.462855   0.464686 \n",
       "  0.0404023    0.0464922    0.0574141   â€¦  0.566188   0.574969   0.572029 \n",
       "  0.550307     0.558475     0.571639       0.465414   0.464826   0.456293 \n",
       "  0.510752     0.475437     0.450426       0.529393   0.523137   0.516547 \n",
       "  0.155832     0.148527     0.142492       0.591004   0.603791   0.617047 \n",
       " -0.00763867  -0.00693555  -0.00948437     0.0364258  0.0384453  0.0402246\n",
       "  0.0705801    0.0627539    0.0641758   â€¦  0.470957   0.467969   0.483119 \n",
       "\n",
       "[:, :, 128, 4] =\n",
       "  0.622875    0.628078    0.616295   â€¦  0.516092   0.506576  0.501588 \n",
       "  0.527492    0.537334    0.534506      0.525955   0.53601   0.53092  \n",
       "  0.539785    0.561094    0.566922      0.464484   0.467469  0.466727 \n",
       "  0.491197    0.499891    0.488832      0.526449   0.530541  0.542711 \n",
       "  0.566662    0.566793    0.571598      0.478713   0.487393  0.499729 \n",
       "  0.545264    0.544424    0.551117   â€¦  0.47135    0.470289  0.499756 \n",
       "  0.554082    0.554781    0.55833       0.660312   0.63817   0.615035 \n",
       "  0.084541    0.0938613   0.149033      0.516393   0.497266  0.49623  \n",
       "  0.535895    0.542045    0.546824      0.515975   0.51423   0.518268 \n",
       "  0.0773965   0.0879941   0.137881      0.537389   0.53616   0.531834 \n",
       "  0.544453    0.547       0.546889   â€¦  0.456834   0.455398  0.445838 \n",
       "  0.506986    0.515041    0.521943      0.565109   0.575598  0.598797 \n",
       "  0.0623633   0.145395    0.260152      0.543824   0.53366   0.532404 \n",
       "  â‹®                                  â‹±  â‹®                             \n",
       "  0.566678    0.580947    0.58109       0.44784    0.451396  0.447002 \n",
       "  0.608455    0.619684    0.608566   â€¦  0.556711   0.521455  0.502939 \n",
       "  0.634572    0.660744    0.661941      0.452793   0.456766  0.452049 \n",
       "  0.0803223   0.0659805   0.0598047     0.598684   0.593877  0.594309 \n",
       "  0.527521    0.526314    0.526084      0.52023    0.518932  0.524465 \n",
       "  0.586818    0.572732    0.587115      0.444051   0.458506  0.485    \n",
       "  0.0667168   0.0687695   0.0669102  â€¦  0.564547   0.567117  0.558707 \n",
       "  0.547088    0.550803    0.560285      0.480389   0.489818  0.491805 \n",
       "  0.5169      0.473666    0.455738      0.525604   0.523008  0.518414 \n",
       "  0.1326      0.158912    0.156705      0.598643   0.599342  0.599576 \n",
       " -0.0110684  -0.0116016  -0.0119512     0.0410449  0.043625  0.0449727\n",
       "  0.0753145   0.0742559   0.0714102  â€¦  0.456545   0.456916  0.47268  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.3.1",
   "language": "julia",
   "name": "julia-1.3"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.3.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
